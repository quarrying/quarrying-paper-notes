# Papers

## [2017] VGGish
----
- https://github.com/tensorflow/models/tree/master/research/audioset/vggish

## [2019] PANN
---
- [2019] PANNs_ Large-Scale Pretrained Audio Neural Networks for Audio Pattern Recognition
- https://github.com/qiuqiangkong/audioset_tagging_cnn
- https://github.com/qiuqiangkong/panns_inference

## [2020] wav2vec
----
- [2020] wav2vec 2.0: A framework for self-supervised learning of speech representations

## [2021] Audio ALBERT
---
- [2021] Audio ALBERT: A Lite BERT for Self-supervised Learning of Audio Representation

## [2024 ICASSP] CED, Consistent Ensemble Distillation
---
- https://github.com/RicherMans/CED
- [2024 ICASSP] Consistent Ensemble Distillation for Audio Tagging

# Datasets

## [2017] AudioSet
---
> Audioset is an audio event dataset, which consists of over 2M human-annotated 10-second video clips. These clips are collected from YouTube, therefore many of which are in poor-quality and contain multiple sound-sources. A hierarchical ontology of 632 event classes is employed to annotate these data, which means that the same sound could be annotated as different labels. For example, the sound of barking is annotated as Animal, Pets, and Dog. All the videos are split into Evaluation/Balanced-Train/Unbalanced-Train set.

被称为声音领域的 ImageNet.

- https://research.google.com/audioset/index.html
- [2017] Audio Set: An ontology and human-labeled dataset for audio events


## [2011 ISMIR] MSD, Million Song Dataset
---
- http://millionsongdataset.com/
- [2011 ISMIR] The Million Song Dataset

