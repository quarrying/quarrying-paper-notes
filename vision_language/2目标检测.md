# Survey
- [2018] Deep Learning for Generic Object Detection_ A Survey
- [handong1587 object-detection](https://handong1587.github.io/deep_learning/2015/10/09/object-detection.html)
- [GitHub awesome-object-detection](https://github.com/amusi/awesome-object-detection)
- [GitHub deep_learning_object_detection](https://github.com/hoya012/deep_learning_object_detection )
- [GitHub ObjectDetectionImbalance](https://github.com/kemaloksuz/ObjectDetectionImbalance)
- [2019] Imbalance Problems in Object Detection_ A Review
- [2017 CVPR] Speed_accuracy trade-offs for modern convolutional object detectors


# NMS

## [2017] SoftNMS
----
- [2017] Improving object detection with one line of code

## [2018] Softer-NMS
----
- [2018] Softer-NMS_ Rethinking Bounding Box Regression for Accurate Object Detection

## [2018] IOU-Guided NMS
----
简言之: 使用预测的 IoU, 而不是分类置信度, 来对检测到的包围盒进行排序.

- [2018] Acquisition of Localization Confidence for Accurate Object Detection

## [2020 AAAI] DIoU NMS
----
- [2020 AAAI] Distance-IoU Loss_ Faster and better learning for bounding box regression

## [2016] A convnet for nonmaximum suppression
---

## [2017] Learnable NMS
----
- [2017] Learning non-maximum suppression

## [2017 ICCV] NMW, Non-maximum weighted
---
- [2017 ICCV] CAD_ Scale Invariant Framework for Real-Time Object Detection

## [2019] WBF, Weighted boxes fusion
---
- [2019] Weighted Boxes Fusion_ ensembling boxes for object detection models


# Label Assignment
---

## [2019 NeurPS] Freeanchor
----
- [2019 NeurPS] Freeanchor: Learning to match anchors for visual object detection

## [2020] Autoassign
---
- [2020] Autoassign: Differentiable label assignment for dense object detection

## [2020 ECCV]  Probabilistic anchor assignment 
---
- [2020 ECCV] Probabilistic anchor assignment with iou prediction for object detection

## [2020 CVPR] ATSS, Adaptive Training Sample Selection
----
> Then, we propose an Adaptive Training Sample Selection (ATSS) to automatically select positive and negative samples according to statistical characteristics of object. It significantly improves the performance of anchor-based and anchor-free detectors and bridges the gap between them.

- [2020 CVPR] Bridging the gap between anchor-based and anchor-free detection via adaptive training sample selection

## [2021 CVPR] OTA, Optimal transport assignment
----
- [2021 CVPR] Ota: Optimal transport assignment for object detection

## [2021] SimOTA
----
SimOTA 是 OTA 的简化版本.

- [2021] Yolox: Exceeding yolo series in 2021

## [2019 CVPR] Guided anchoring
----
- [2019 CVPR] Region proposal by guided anchoring

## [2018 NeurIPS]  Metaanchor
----
- [2018 NeurIPS] Metaanchor: Learning to detect objects with customized anchors

## [2018] Anchor box optimization
----
- [2018] Anchor box optimization for object detection

## [2021] POTO, Prediction-aware One-To-One
--- 
文章认为当前主流检测器需要使用 NMS 消除冗余框的原因在于: 使用了一对多 (一个 gt 对应多个前景样本) 的 label assignment.

> As shown in Fig. 1, most of fully convolutional detectors [22, 46, 50, 21] adopt a one-to-many label assignment rule, i.e., assigning many predictions as foreground samples for one ground-truth instance. This rule provides adequate foreground samples to obtain a strong and robust feature representation. Nevertheless, the massive foreground samples lead to duplicate predicted boxes for a single instance, which prevents end-to-end detection.

POTO 本质上也是一种二分图匹配, 但匹配代价与之前的不一样.

文中提到的下面一句话, 不甚明白:
> However, foreground loss typically needs additional weights to alleviate optimization issues, e.g., unbalanced training samples and joint training of multiple tasks.

- [2021] End-to-End Object Detection with Fully Convolutional Network
- https://github.com/Megvii-BaseDetection/DeFCN

## [2021 CVPR] TAL, Task Alignment Learning
----
- [2021 CVPR] Tood: Task-aligned one-stage object detection

## [2019] IoU-balanced Sampling
----
- [2019] Libra R-CNN_ Towards Balanced Learning for Object Detection


# ROI Operation
---

## [2015] ROI Pooling
----
> RoI max pooling works by dividing the h × w RoI window into an H × W grid of sub-windows of approximate size h/H × w/W and then max-pooling the values in each sub-window into the corresponding output grid cell. Pooling is applied independently to each feature map channel, as in standard max pooling. The RoI layer is simply thespecial-case of the spatial pyramid pooling layer used in SPPnets [11] in which there is only one pyramid level.

- [2015] Fast R-CNN

## RoIWrap Pooling
----

## ROIAlign Pooling
----
- [2017 ICCV] Mask r-cnn
- [RoIPooling、RoIAlign笔记](https://www.cnblogs.com/wangyong/p/8523814.html)

## PSROI Pooling, Position-sensitive ROI Pooling
---
- [2016] R-FCN_ Object Detection via Region-based Fully Convolutional Networks

## Precise ROI Pooling, PrRoI Pooling
--- 
- [2018 ECCV] Acquisition of Localization Confidence for Accurate Object Detection

## RoI transform layer
----
- [2018 ACCV] Textnet_ Irregular text reading from images with an end-to-end trainable network

## crop_and_resize
---
> we use Tensorflow's "crop_and_resize" operation which uses bilinear interpolation to resample part of an image onto a fixed sized grid.
>>[2017 CVPR] Speed_accuracy trade-offs for modern convolutional object detectors

> The first notable change follows Huang et al. [4]. Instead of using the RoI pooling layer, we use the crop and resize operator, which crops and resizes feature maps to 14 × 14, and then max-pool them to 7 × 7 to match the input size of fc6.
>> [2017] An Implementation of Faster RCNN with Study for Region Sampling

- [2017 CVPR] Speed_accuracy trade-offs for modern convolutional object detectors
- [2017] An Implementation of Faster RCNN with Study for Region Sampling
- <https://tensorflow.google.cn/api_docs/python/tf/image/crop_and_resize>


# Loss

## [2016 ACM MM] IoU loss
----
- [2016 ACM MM] UnitBox_ An advanced object detection network

## [2019 CVPR] GIoU loss
----
- [2019 CVPR] Generalized intersection over union_ A metric and a loss for bounding box regression

## [2020 AAAI] DIoU loss, CIoU loss
---
- [2020 AAAI] Distance-IoU Loss_ Faster and better learning for bounding box regression

## [2021 NeurIPS] α-IoU Loss
----
- [2021 NeurIPS] α-iou: A family of power intersection over union losses for bounding box regression

## [2022] SIoU Loss
----
- [2022] Siou loss: More powerful learning for bounding box regression

## [2018 CVPR] bounded iou loss
---
- [2018 CVPR] Improving object localization with fitness nms and bounded iou loss

## [2020 ECCV] PIoU Loss
----
- [2020 ECCV] PIoU Loss_ Towards Accurate Oriented Object Detection in Complex Environments

## [2021 CVPR] Varifocal Loss, VFL
----
- [2021 CVPR] Varifocalnet: An iou-aware dense object detector


# Task alignment
解决问题: Misalignment between confidence and localization accuracy

> the classification score is not strongly correlated with the precision of box localization

## [2020] Generalized Focal Loss, GFL, GFLv2
----
> GFL and GFLv2 point out that the classification and localization branches are separately trained but compositely used in inference, so they merge the localization representation into the classification branch for a joint optimization.

- [2020] Generalized Focal Loss_ Learning Qualified and Distributed Bounding Boxes for Dense Object Detection
- [2020] Generalized Focal Loss V2_ Learning Reliable Localization Quality Estimation for Dense Object Detection

## [2018 ECCV] IoUNet
----
Figure 2(a) 揭示了: 在 NMS 之前, det_boxes 和其匹配的 gt_boxes 的 iou 与 det_boxes 的分类置信度之间的关系, 两者并不是强相关的.

- [2018 ECCV] Acquisition of Localization Confidence for Accurate Object Detection


# Detetector Neck

## [2017 CVPR] FPN
---
- [2017 CVPR] Feature Pyramid Networks for Object Detection

## [2019]ASFF, adaptively spatial feature fusion
----
- [2019] Learning Spatial Fusion for Single-Shot Object Detection
- https://github.com/ruinmessi/ASFF

## [2019 CVPR] NAS-FPN
----
- [2019 CVPR] NAS-FPN_ Learning scalable feature pyramid architecture for object detection

## [2020] RFP
---
- [2020] Detectors_ Detecting objects with recursive feature pyramid and switchable atrous convolution.

## [2020 CVPR] BiFPN
----
- [2020 CVPR] Efficientdet: Scalable and efficient object detection

## [2018 CVPR] PAN, PANet, Path aggregation network
----
- [2018 CVPR] Path aggregation network for instance segmentation
- https://github.com/ShuLiu1993/PANet


# SSD Series

## SSD
----
传统 SSD 的骨干网络为 VGG. SSD predict objects at multiple layers of the network without merging features.

- [2015] SSD_ Single Shot MultiBox Detector
- https://github.com/weiliu89/caffe/tree/ssd (该项目实现了一个 Caffe 新层, Permute)
- https://github.com/balancap/SSD-Tensorflow
- https://github.com/amdegroot/ssd.pytorch


## DSSD, Deconvolutional single shot detector
---
- [2017] DSSD_ Deconvolutional single shot detector

## Others
----
- [2017] Enhancement of SSD by concatenating feature maps for object detection
- [2017] Feature-fused SSD_ fast detection for small objects
- [2018] Tiny SSD_ A Tiny Single-shot Detection Deep Convolutional Neural Network for Real-time Embedded Object Detection
- [2018] Ensemble-based Adaptive Single-shot Multi-box Detector
- *MobileNet-SSD*: [2017] Mobilenets_ Efficient convolutional neural networks for mobile vision applications
- *MobileNetV2-SSDLite*: [2018 CVPR] Mobilenetv2_ Inverted residuals and linear bottlenecks
- *MobileNeXt*: [2020] MobileNeXt_ Rethinking Bottleneck Structure for Efficient Mobile Network Design
    - https://github.com/Andrew-Qibin/ssdlite-pytorch-mobilenext


# R-CNN Series

## R-CNN
----
- [2014] Rich feature hierarchies for accurate object detection and semantic segmentation

## Fast R-CNN
----
Fast RCNN 使用 selective search 进行 region proposal.
- [2015] Fast R-CNN

## Faster R-CNN, faster rcnn
----
Faster R-CNN 由两部分构成, 第一部分称为 RPN, 第二部分称为 R-CNN (有的文献称为 box classifier).

RPN 是全卷积的, 输出通道数 (或者说输出类别) 为 2 (前景和背景).

> We note that our algorithm allows the use of anchor boxes that are larger than the underlying receptive field when predicting large proposals. Such predictions are not impossible — one may still roughly infer the extent of an object if only the middle of the object is visible.

**References**
- [2015 NIPS] Faster R-CNN_ Towards Real-Time Object Detection with Region Proposal Networks
- https://github.com/rbgirshick/py-faster-rcnn
- https://github.com/endernewton/tf-faster-rcnn
- https://github.com/sanghoon/pva-faster-rcnn
- https://github.com/CharlesShang/TFFRCNN/

## Light-Head R-CNN
----
- [2017 @Face++] Light-Head R-CNN_ In Defense of Two-Stage Object Detector

## Region Sampling
----
> NMS implicitly biases the sampling procedure toward smaller regions. Intuitively, it is more likely for large regions to overlap than small regions, so large regions have a higher chance to be suppressed.

- [2017] An Implementation of Faster RCNN with Study for Region Sampling


# YOLO Series
---
Framework | Backbone
----------|----------
YOLOv1    | /
YOLOv2    | Darknet-19
YOLOv3    | Darknet-53
YOLOv4    | CSPDarknet53

## YOLOv1
----
YOLOv1 可以视作一种 anchor-free 的方法.

- [2015] You Only Look Once_ Unified, Real-Time Object Detection

## YOLOv2
----
- [2016] YOLO9000_ Better, Faster, Stronger

## YOLOv3
----
- [2018] YOLOv3_ An Incremental Improvement
- https://github.com/ultralytics/yolov3

## Yolo-lite
---
- [2018] Yolo-lite_ a real-time object detection algorithm optimized for non-gpu computers

## YOLOv4
---
- [2020] YOLOv4_ Optimal Speed and Accuracy of Object Detection
- https://github.com/AlexeyAB/darknet

## YOLOv5
---
- https://github.com/ultralytics/YOLOv5

## Scaled-YOLOv4
---
- [2020] Scaled-YOLOv4_ Scaling Cross Stage Partial Network

## Yolov6
----
美团公司算法团队提出的算法.

- [2022] YOLOv6_ A Single-Stage Object Detection Framework for Industrial Applications

## PP-YOLOE
----
- [2022] Pp-yoloe: An evolved version of yolo

## Others
---
- https://github.com/byfate/Stronger-yolo-pytorch


# Anchor-free
有文献认为: There are two types of anchorfree detectors: anchor point-based (如 FCOS) and keypoint-based (如 cornernet).

**个人认为**: anchor-free 并不是没有 anchor, 只是没有 anchor box.


## FCOS, Fully Convolutional One-Stage
----
> In anchor-based detectors, the anchor boxes can be viewed as pre-defined sliding windows or proposals, which are classified as positive or negative patches, with an extra offsets regression to refine the prediction of bounding box locations. Therefore, the anchor boxes in these detectors may be viewed as training samples.

该论文引入了 **BPR** (Best Possible Recall) 的概念, 其定义如下:
> Here BPR is defined as the ratio of the number of ground-truth boxes a detector can recall at the most divided by all ground-truth boxes. A ground-truth box is considered being recalled if the box is assigned to at least one sample (i.e., a location in FCOS or an anchor box in anchor-based detectors) during training.

**References**:
- https://github.com/tianzhi0549/FCOS
- [2019] FCOS_ Fully Convolutional One-Stage Object Detection

## CenterNet
----
- https://github.com/xingyizhou/centernet
- [2019] Objects as Points

## CornerNet
---
CornerNet 的缺点是后处理复杂. 

- [2018 ICCV] CornerNet_ Detecting objects as paired keypoints
- https://github.com/umich-vl/CornerNet

## CornerNet-Lite
---
- [2019] CornerNet-Lite_ Efficient keypoint based object detection

## RepPoints
---
- [2019 ICCV] RepPoints_ Point set representation for object detection

## RepPoints v2
----
- [2020] RepPoints v2_ Verification Meets Regression for Object Detection

## DenseBox
---
> The family of detectors have been considered unsuitable for generic object detection due to difficulty in handling overlapping bounding boxes and the recall being relatively low.

- [2015] Densebox: Unifying landmark localization with end to end object detection

## FSAF, Feature Selective Anchor-Free
----
本文提出一种根据损失函数值进行特征层选择的方法.

- [2019 CVPR] Feature Selective Anchor-Free Module for Single-Shot Object Detection


# Detection and NAS

## DetNAS
---
- [2019 NeurIPS] DetNAS: Backbone search for object detection

## NAS-FPN
---
- [2019 CVPR] NAS-FPN: Learning scalable feature pyramid architecture for object detection

## NAS-FCOS
---
- [2019] NAS-FCOS: Fast neural architecture search for object detection


# Detection with transformer

## [2020] DETR, DEtection TRansformer
---
!TODO: 精读

**Pros**: DETR eliminates the hand-designed anchor and NMS components in the traditional detection pipeline.

**Cons**: DETR suffers from two major issues: slow training convergence and hard-to-optimize queries.

### inputs
- encoder 的输入是 backbone 的输出.
- decoder 的输入是全零向量.

### position embedding / object queries
- encoder 中每个自注意力层的 query 和 key 都需要加 position embedding, 但 value 不用加.
- decoder 中每个自注意力层的 query 和 key 都需要加 object query, 但 value 不用加.
- decoder 中每个交叉注意力层的 query 需要加 object queries, key 需要加 position embedding, 但 value 不用加.

在官方实现中, position embedding 是固定的, object queries 是可学习的.

### 疑问
- DETR 中的 Transformer 相对于标准的 Transformer 有哪些区别?
- DETR 中 matching cost 使用概率, 而 loss 中使用对数概率, 这是为什么?
- DETR 中, query 和 key 需要加 position embedding 或 object queries, 而 value 不需要加, 而且是每个注意力层都是如此操作, 但在标准 Transformer 中 query, key, value 只需要在输入时加 position embedding. 如何理解两者之间的不一致?


### 参考
- [2020] End-to-end object detection with transformer
- https://github.com/facebookresearch/detr
- Why positional encoding is added to different role in encoder and decoder.
    - https://github.com/facebookresearch/detr/issues/607
- Question about object queries
    - https://github.com/facebookresearch/detr/issues/178

## [2020] Deformable DETR
----
- [2020] Deformable detr: Deformable transformers for end-to-end object detection
- https://github.com/fundamentalvision/Deformable-DETR
- https://pypi.org/project/MultiScaleDeformableAttention/

## [2022] DAB-DETR
---
- [2022 ICLR] DAB-DETR: Dynamic anchor boxes are better queries for DETR

## [2022] DN-DETR
----
- [2022 CVPR] Dn-detr: Accelerate detr training by introducing query denoising
- https://github.com/IDEA-Research/DN-DETR/

## [2022] DINO, DETR with Improved DeNoising
---
- [2022] DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection

## [2023 @Baidu] RT-DETR, Real-Time DEtection TRansformer
----
- [2023] DETRs Beat YOLOs on Real-time Object Detection

## [2022] ViTDet
---
提出一个非层次的基于 ViT 的目标检测 backbone.

- [2022] Exploring Plain Vision Transformer Backbones for Object Detection

## [2025] DEIMv2
---
提出一个名为 Spatial Tuning Adapter (STA) 的结构将 DinoV3 的单尺度特征转化为多尺度特征, 以适配于目标检测任务.

- [2025] Real-Time Object Detection Meets DINOv3


# Distill

## [2017 NIPS] Learning efficient object detection models with knowledge distillation
---

## [2021] LGD: Label-guided Self-distillation for Object Detection
----


# Rotated Bounding Box

## [2017] Learning a rotation invariant detector with rotatable bounding box
---

## [2018] Multiscale rotated bounding box-based deep learning method for detecting ship targets in remote sensing images
---

## [2018 CVPR] Rotation-sensitive regression for oriented scene text detection
---

## [2019 CVPR]  Learning roi transformer for detecting oriented objects in aerial images
---

## [2019] R3det_ Refined single-stage detector with feature refinement for rotating object
---

## [2019 CVPR] Scrdet_ Towards more robust detection for small, cluttered and rotated objects
---

## [2020 ECCV] PIoU Loss_ Towards Accurate Oriented Object Detection in Complex Environments
---
- https://github.com/clobotics/piou


# Others

## OverFeat
---
- [2014] OverFeat_ Integrated Recognition, Localization and Detection using Convolutional Networks

## SPPNet
---
- [2014 ECCV] Spatial pyramid pooling in deep convolutional networks for visual recognition

## MultiBox
---
- [2014 CVPR] Scalable Object Detection using Deep Neural Networks

## MR-CNN
---
- [2015 ICCV] Object detection via a multi-region & semantic segmentation-aware cnn model

## ION
---
- [2015] Inside-Outside Net_ Detecting Objects in Context with Skip Pooling and Recurrent Neural Networks

## HyperNet
---
- [2016 CVPR] HyperNet_ Towards Accurate Region Proposal Generation and Joint Object Detection

## PVANet
---
- [2016 NIPS Workshop] PVANet_ Lightweight Deep Neural Networks for Real-time Object Detection

## R-FCN
---
- [2016] R-FCN_ Object Detection via Region-based Fully Convolutional Networks

## G-CNN
---
- [2015] G-CNN_ an Iterative Grid Based Object Detector

## MS-CNN
---
- [2016 ECCV] A unified multiscale deep convolutional neural network for fast object detection

## OHEM
---
- [2016 CVPR] Training region-based object detectors with online hard example mining

## SqueezeDet
---
- [2016] SqueezeDet_ Unified, Small, Low Power Fully Convolutional Neural Networks for Real-Time Object Detection for Autonomous Driving

## RetinaNet, Focal Loss
---
sigmoid 交叉熵损失的定义为:
$$\begin{aligned}
\mathrm{BCE}(p,y) 
&= \begin{cases}
        -\log(p) & y = 1 \\ 
        -\log(1 - p) & y = 0
    \end{cases}\\
&= -y\log({p}) - (1 - y)\log({1 - p}) \\
&= -\log(yp + (1 - y)(1 - p))\\
\end{aligned}$$

为了标记便利, 定义:
$$p_t = yp + (1 - y)(1 - p) = 
\begin{cases}
p & y = 1 \\
1 - p & y = 0
\end{cases}$$

则 $\mathrm{BCE}(p,y) = \mathrm{BCE}(p_t) = -\log(p_t)$, 

Focal Loss 的定义为:
$$\mathrm{FL}(p_t) = -\alpha_t(1 - p_t)^\gamma \log({p_t})$$

其中 $\alpha_t$ 的定义仿照 $p_t$ 的定义, 如下:
$$\alpha_t = y\alpha + (1 - y)(1 - \alpha) = \begin{cases}
\alpha & y = 1 \\
1 - \alpha & y = 0
\end{cases}$$

Focal Loss 包括两个参数: 1) $\alpha \in [0,1]$,  In practice $\alpha$ may be set by inverse class frequency or treated as a hyperparameter to set by cross validation. 该参数可以用来平衡正负样本的重要性. 2) $\gamma >= 0$, 可以用来 down-weight easy examples and thus focus training on hard negatives. the focal loss performs the opposite role of a robust loss: it focuses training on a sparse set of hard examples.

**结论 1** : 若设 $\alpha_t = 1$, 则有

$$\mathrm{BCE}(p_t) \geq \mathrm{FL}(p_t)$$

当 $\gamma = 0$ 时, 等式成立. 该结论表明, Focal Loss 在数值上一般要小于 BCE Loss.

**结论 2** : 
$$\begin{aligned}1 - p_t 
&= 1 - yp - (1 - y)(1 - p) \\
&= (1 - y)p + y(1 - p)
\end{aligned}$$
该结论可能在代码实现时有用.

### RetinaNet 网络结构
- 目标分类子网络和包围盒回归子网络的参数不共享.
- 目标分类/包围盒回归各级金字塔子网络参数共享.

**Reference**:
- [2017] Focal Loss for Dense Object Detection
- https://github.com/yhenon/pytorch-retinanet

## DetNet
---
- [2018 ECCV] DetNet_ A Backbone network for Object Detection

## Pelee
---
- [2018] Pelee_ A Real-Time Object Detection System on Mobile Devices
- https://github.com/Robert-JunWang/Pelee

## IOU-Net
---
- [2018 ECCV] Acquisition of Localization Confidence for Accurate Object Detection

## RFB-Net
---
- [2018 ECCV] Receptive Field Block Net for Accurate and Fast Object Detection

## RefineDet
---
- [2018 CVPR] Single-Shot Refinement Neural Network for Object Detection

## Tiny-DSOD
---
- [2018] Tiny-dsod: Lightweight object detection for resource-restricted usages

## Trident
---
- [2019] Scale-Aware Trident Networks for Object Detection

## ThunderNet
---
- [2019 ICCV] ThunderNet_ Towards Real-time Generic Object Detection

## DuBox
---
- [2019] DuBox_ No-Prior Box Objection Detection via Residual Dual Scale Detectors

## AlignDet
---
- [2019] Revisiting Feature Alignment for One-stage Object Detection

## M2Det
---
- [2019] M2Det_ A Single-Shot Object Detector based on Multi-Level Feature Pyramid Network
- https://github.com/qijiezhao/M2Det

## EfficientDet
---
- [[2019] EfficientDet_ Scalable and Efficient Object Detection](https://arxiv.org/abs/1911.09070)
- https://github.com/toandaominh1997/EfficientDet.Pytorch
- https://github.com/signatrix/efficientdet
- https://github.com/zylo117/Yet-Another-EfficientDet-Pytorch
- https://github.com/google/automl/tree/master/efficientdet

## Spinenet
---
- [2020 CVPR] Spinenet_ Learning scale-permuted backbone for recognition and localization

## CSPNet
---
- [2020 CVPRW] CSPNet_ A new backbone that can enhance learning capability of CNN

## LRF
---
- [2019 ICCV] Learning Rich Features at High-Speed for Single-Shot Object Detection
- https://github.com/vaesl/LRF-Net

## PRN
---
- [2019 ICCVW] Enriching variety of layer-wise learning information by gradient combination

## SNIP
---
- [2018 CVPR] An analysis of scale invariance in object detection snip
- [2018 NIPS] Sniper: Efficient multi-scale training

## NanoDet-Plus
---
- [2021] NanoDet-Plus: Super fast and high accuracy lightweight anchor-free object detection model

## DPM (写于 2014)
----
DPM-related methods are computationally expensive and may usually require expensive annotation in the training stage.

$\vec v_i^T = \left( {x_i^*,y_i^*} \right) - \left( {x_0^*,y_0^*} \right)$, 其中 $\left( {x_i^*,y_i^*} \right)$ 为模型中 $part_i$ 的位置, $\left( {x_0^*,y_0^*} \right)$ 为模型中 root 的位置, 故 $\vec v_i^T$ 表示 $part_i$ 相对于 root 的位置.

假设目标的 root 位置等于模型的 root 位置, 即 $\left( {x_0^*,y_0^*} \right) = \left( {{x_0},{y_0}} \right)$, 则

$$\begin{aligned}
  \left( {d{x_i},d{y_i}} \right) &= \left( {{x_i},{y_i}} \right) - \left( {x_i^*,y_i^*} \right) - \left( {{x_0},{y_0}} \right) \\ 
   &= \left( {{x_i},{y_i}} \right) - \left[ {\vec v_i^T + \left( {{x_0},{y_0}} \right)} \right] - \left( {{x_0},{y_0}} \right) \\ 
   &= \left( {{x_i},{y_i}} \right) - \left[ {2\left( {{x_0},{y_0}} \right) + \vec v_i^T} \right] \\ 
\end{aligned}$$

上面的公式存疑.

**References**:
- [2008 CVPR] A Discriminatively Trained, Multiscale, Deformable Part Model
- [2010 PAMI] Object Detection with Discriminatively Trained Part-Based Models
- [2010 CVPR] Cascade Object Detection with Deformable Part Models


# Dataset

## Overview
---

Dataset        | Images | Boxes    | Categories | Boxes/image
---------------|--------|----------|------------|------------
PASCAL VOC     | 11.5K  | 27K      | 20         | 2.4
ImageNet All   | 477K   | 534K     | 200        | 1.1
ImageNet Dense | 80K    | 186K     | 200        | 2.3
COCO           | 123K   | 896K     | 80         | 7.3
Objects365 v1  | 638K   | 10,101K  | 365        | 15.8
Objects365 v2  | 1800K  | 29,000K  | 365        | 14.8

## TJU-DHD
---
**References**:
- [2020 TIP] TJU-DHD_ A Diverse High-Resolution Dataset for Object Detection


## Objects365, Object365, O365
---
覆盖 365 个类别数量.
- v1: 总共包含 63 万张图像数量, 高达 1000 万的框数. 
- v2: 总共包含 200 万张图像数量, 高达 3000 万的框数.

Objects365 包含 COCO 和 PASCAL VOC 中的标签. Objects365 的标注文件格式和 COCO 数据集一样.

> Intuitively, the smaller weights usually require a smaller learning rate to train.

**注意**: 
- 该数据集标签存在一些拼写错误 (如 `Ballon`, `Buttefly`, `Campel`, `Mushroon` 等).
- 数据集中 `Mouse` 实为鼠标, 而不是老鼠.

**References**:
- [ICCV 2019] Objects365_ A Large-scale, High-quality Dataset for Object Detection 
- http://www.objects365.org/overview.html
- https://data.baai.ac.cn/details/Objects365_2020


## PASCAL3D+
---
**References**:
- [2014 WACV] Beyond pascal_ A benchmark for 3d object detection in the wild


## ODinW, Object Detection in the Wild
---
- [2022] Elevater: A benchmark and toolkit for evaluating language-augmented visual models


