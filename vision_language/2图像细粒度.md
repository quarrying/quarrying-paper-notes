# Workshop
- FGVC4 workshop at CVPR 2017
- FGVC5 workshop at CVPR 2018
- FGVC6 workshop at CVPR 2019
- FGVC7 workshop at CVPR 2020
- FGVC8 workshop at CVPR 2021
- FGVC9 workshop at CVPR 2021

# Papers

## [2016] Learning a Discriminative Filter Bank within a CNN for Fine-grained Recognition
---
DFL-CNN 主要包括骨干网络和分支网络. 常见的经典 CNN 都可以用来作为骨干网络, 其用来提取基础特征. 分支网络分为三个部分: 1) G-Stream: 用来提取全局特征; 2) P-Stream, 用来提取判别性的块特征; 3) Side Branch: 用来提取类依赖的判别性的块特征. 可以在骨干网络的多个尺度上引出分支网络, 最后各尺度的各分支的输出特征进行加权融合, 得到最终的特征, 送入分类器进行分类. DFL-CNN 的最终特征融合了多尺度的全局和局部特征, 具有较高的可判别性. 

## [2018 ECCV] NTS-Net, Navigator-Teacher-Scrutinizer Network
----
论文的核心是: Navigation loss.

- [2018 ECCV] Learning to Navigate for Fine-grained Classification

## [2019 CVPR] DCL, Destruction and Construction Learning
----
!TODO: 精读

- [2019 CVPR] Destruction and Construction Learning for Fine-grained Image Recognition

## [2019] WS-DAN, Weakly Supervised Data Augmentation Network
----
- [2019] See better before looking closer: Weakly supervised data augmentation network for fine-grained visual classification

## [2020 ECCV] PMG, progressive multi-granularity
---
- [2020 ECCV] Fine-grained visual classification via progressive multi-granularity training of jigsaw patches

## [2020 CVPR] BBN, Bilateral-Branch Network
----
- [2020 CVPR] BBN_ Bilateral-Branch Network with Cumulative Learning for Long-Tailed Visual Recognition

## [2022 CVPR] P2P-Net
----
- [2022 CVPR] Fine-Grained Object Classification via Self-Supervised Pose Alignment

## [2023] GIST, Generating Image-Specific Text
---
该论文创新之处应该是: 提出了对一种生成 image caption (或者说图文对数据集) 的方法. 不是直接使用 caption 模型, 而是使用大语言模型先生成 class-specfic 的 prompt, 然后利用 CLIP 为每张图像选择合适的 caption.

- [2023] GIST: Generating Image-Specific Text for Fine-grained Object Classification
- https://github.com/emu1729/GIST


# Datasets

Dataset name  | Year | Meta-class       | images  | categories | BBox | Part anno. | HRCHY | ATR | Texts
--------------|------|------------------|---------|------------|------|------------|-------|-----|-------
Oxford flower | 2008 | Flowers          | 8,189   | 102        |      |            |       |     | [x]
CUB200        | 2011 | Birds            | 11,788  | 200        | [x]  | [x]        |       | [x] | [x]
Stanford Dog  | 2011 | Dogs             | 20,580  | 120        | [x]  |            |       |     | 
Stanford Car  | 2013 | Cars             | 16,185  | 196        | [x]  |            | [x]   |     | 
FGVC Aircraft | 2013 | Aircrafts        | 10,000  | 100        | [x]  |            |       |     | 
Birdsnap      | 2014 | Birds            | 49,829  | 500        | [x]  | [x]        |       | [x] | 
NABirds       | 2015 | Birds            | 48,562  | 555        | [x]  | [x]        |       |     | 
DeepFashion   | 2016 | Clothes          | 800,000 | 1,050      | [x]  | [x]        |       | [x] | 
Fru92         | 2017 | Fruits           | 69,614  | 92         |      |            | [x]   |     | 
Veg200        | 2017 | Vegetable        | 91,117  | 200        |      |            | [x]   |     | 
iNat2017      | 2017 | Plants & Animals | 859,000 | 5,089      | [x]  |            | [x]   |     | 
RPC           | 2019 | Retail products  | 83,739  | 200        | [x]  |            | [x]   |     | 

Note that **BBox** indicates whether this dataset provides object bounding box supervisions. **Part anno.** means providing the key part localizations. **HRCHY** corresponds to hierarchical labels. **ATR** represents the attribute labels (e.g., wing color, male, female, etc). **Texts** indicates whether fine-grained text descriptions of images are supplied.

**References**
- http://www.weixiushen.com/project/Awesome_FGIA/Awesome_FGIA.html


## Aircrafts
---
**References**:
- http://www.robots.ox.ac.uk/~vgg/data/fgvc-aircraft/
- [2013] Fine-Grained Visual Classification of Aircraft


## Stanford Cars
---
The Cars dataset contains 16,185 images of 196 classes of cars. The data is split into 8,144 training images and 8,041 testing images, where each class has been split roughly in a 50-50 split. Classes are typically at the level of Make, Model, Year, e.g. 2012 Tesla Model S or 2012 BMW M3 coupe.

**References**:
- [2013 ICCVW] 3d object representations for fine-grained categorization
- http://ai.stanford.edu/~jkrause/cars/car_dataset.html

