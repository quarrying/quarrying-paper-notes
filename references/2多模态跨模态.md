# Tasks
- Visual Grounding (VG)
- Grounded Captioning (GC)
- Image-Text Matching (ITM)
- Image Captioning (IC)
- Visual Question Answering (VQA)
- Image-Text Retrieval
- Referring Expression Comprehension
- Word-Region Alignment (WRA)
- Visual Commonsense Reasoning (VCR)
- Visual Entailment
- Natural Language for Visual Reasoning (NLVR^2)
- phrase grounding (object referring): 给出一张图片和一个自然语言描述的问题, 在图片中定位问题中所提到的物体.
- Temporal Activity Localization by Language: 给定一个query (包含对 activity 的描述), 找到对应动作 (事件) 的起止时间.
    - Temporal Activity Localization by Language 实际上就是下文中的 TVG?
- Spatio-temporal object referring by language: 给定一个query (包含对 object/person 的描述), 在时空中找到连续的 bounding box (也就是一个 tube).
- Temporal video grounding (TVG) aims to localize a target segment in a video according to a given sentence query. 
- vision-and-language pre-training (VLP)

# Papers
## [2022] Language Models are General-Purpose Interfaces
---

## [2022 ICML] OFA_ Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework
---

## [2021] CLIP, Contrastive Language-Image Pre-training
----
自行构建了一个新的数据集 WebImageText, 简称为 WIT.

> CLIP is pre-trained to predict if an image and a text snippet are paired together in its dataset.

- [2021] Learning Transferable Visual Models From Natural Language Supervision

# Datasets & Challenges

## Person In Context
----
- http://picdataset.com/challenge/index/

## ActivityNet Captions
----

## Charades-STA
----
- [2016 ECCV] Hollywood in homes: Crowdsourcing data collection for activity understanding

## Visual Genome, VG
----
- [2017 IJCV] Visual genome: Connecting language and vision using crowdsourced dense image annotations

## Conceptual Captions, CC
----
- [2018 ACL] Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning

## SBU Captions
----
- [2011 NeurIPS] Im2text: Describing images using 1 million captioned photographs

## COCO captions
----
- [2015] Microsoft COCO captions: Data collection and evaluation server

## TextCaps
----
- [2020 ECCV] TextCaps: a Dataset for Image Captioningwith Reading Comprehension

## nocaps, novel object captioning at scale
----
- https://nocaps.org/

