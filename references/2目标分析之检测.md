# 代码
- [TensorFlow object detection API](https://github.com/tensorflow/models/tree/master/research/object_detection)
- [Facebook Detectron](https://github.com/facebookresearch/Detectron)
- [Facebook detectron2](https://github.com/facebookresearch/detectron2)
- [CUHK mmdetection](https://github.com/open-mmlab/mmdetection)
- [TuSimple simpledet](https://github.com/TuSimple/simpledet)
- [maskrcnn-benchmark](https://github.com/facebookresearch/maskrcnn-benchmark)
- [nms](https://bitbucket.org/tomhoag/nms/src/master/)


# Survey
- [2018] Deep Learning for Generic Object Detection_ A Survey
- [handong1587 object-detection](https://handong1587.github.io/deep_learning/2015/10/09/object-detection.html)
- [GitHub awesome-object-detection](https://github.com/amusi/awesome-object-detection)
- [GitHub deep_learning_object_detection](https://github.com/hoya012/deep_learning_object_detection )
- [GitHub ObjectDetectionImbalance](https://github.com/kemaloksuz/ObjectDetectionImbalance)
- [2019] Imbalance Problems in Object Detection_ A Review
- [2017 CVPR] Speed_accuracy trade-offs for modern convolutional object detectors


# NMS

## SoftNMS
----
- [2017] Improving object detection with one line of code

## Softer-NMS
----
- [2018] Softer-NMS_ Rethinking Bounding Box Regression for Accurate Object Detection

## IOU-Guided NMS
----
简言之: 使用预测的 IoU, 而不是分类置信度, 来对检测到的包围盒进行排序.

- [2018] Acquisition of Localization Confidence for Accurate Object Detection

## DIoU NMS
----
- [2020 AAAI] Distance-IoU Loss_ Faster and better learning for bounding box regression

## [2016] A convnet for nonmaximum suppression
---

## Learnable NMS
----
- [2017] Learning non-maximum suppression

## NMW, Non-maximum weighted
- [2017 ICCV] CAD_ Scale Invariant Framework for Real-Time Object Detection

## WBF, Weighted boxes fusion
---
- [2019] Weighted Boxes Fusion_ ensembling boxes for object detection models

## [2014 ACCV] Non-maximum suppression for object detection by passing messages between windows
---

# Label Assignment
---

## Freeanchor
----
- [2019 NeurPS] Freeanchor: Learning to match anchors for visual object detection

## Autoassign
---
- [2020] Autoassign: Differentiable label assignment for dense object detection

## Probabilistic anchor assignment 
---
- [2020 ECCV] Probabilistic anchor assignment with iou prediction for object detection

## ATSS, Adaptive Training Sample Selection
----
> Then, we propose an Adaptive Training Sample Selection (ATSS) to automatically select positive and negative samples according to statistical characteristics of object. It significantly improves the performance of anchor-based and anchor-free detectors and bridges the gap between them.

- [2020 CVPR] Bridging the gap between anchor-based and anchor-free detection via adaptive training sample selection

## OTA, Optimal transport assignment
----
- [2021 CVPR] Ota: Optimal transport assignment for object detection

## SimOTA
----
- [2021] Yolox: Exceeding yolo series in 2021

## Guided anchoring
----
- [2019 CVPR] Region proposal by guided anchoring

## Metaanchor
----
- [2018 NeurIPS] Metaanchor: Learning to detect objects with customized anchors

## Anchor box optimization
----
- [2018] Anchor box optimization for object detection

## POTO, Prediction-aware One-To-One
--- 
文章认为当前主流检测器需要使用 NMS 消除冗余框的原因在于: 使用了一对多 (一个 gt 对应多个前景样本) 的 label assignment.

> As shown in Fig. 1, most of fully convolutional detectors [22, 46, 50, 21] adopt a one-to-many label assignment rule, i.e., assigning many predictions as foreground samples for one ground-truth instance. This rule provides adequate foreground samples to obtain a strong and robust feature representation. Nevertheless, the massive foreground samples lead to duplicate predicted boxes for a single instance, which prevents end-to-end detection.

POTO 本质上也是一种二分图匹配, 但匹配代价与之前的不一样.

文中提到的下面一句话, 不甚明白:
> However, foreground loss typically needs additional weights to alleviate optimization issues, e.g., unbalanced training samples and joint training of multiple tasks.

- [2021] End-to-End Object Detection with Fully Convolutional Network
- https://github.com/Megvii-BaseDetection/DeFCN


# Sampling
---

## IoU-balanced Sampling
----
- [2019] Libra R-CNN_ Towards Balanced Learning for Object Detection


# ROI Operation
---

## ROI Pooling
----
> RoI max pooling works by dividing the h × w RoI window into an H × W grid of sub-windows of approximate size h/H × w/W and then max-pooling the values in each sub-window into the corresponding output grid cell. Pooling is applied independently to each feature map channel, as in standard max pooling. The RoI layer is simply thespecial-case of the spatial pyramid pooling layer used in SPPnets [11] in which there is only one pyramid level.

- [2015] Fast R-CNN

## RoIWrap Pooling
----

## ROIAlign Pooling
----
- [2017 ICCV] Mask r-cnn
- [RoIPooling、RoIAlign笔记](https://www.cnblogs.com/wangyong/p/8523814.html)

## PSROI Pooling, Position-sensitive ROI Pooling
---
- [2016] R-FCN_ Object Detection via Region-based Fully Convolutional Networks

## Precise ROI Pooling, PrRoI Pooling
--- 
- [2018 ECCV] Acquisition of Localization Confidence for Accurate Object Detection

## RoI transform layer
----
- [2018 ACCV] Textnet_ Irregular text reading from images with an end-to-end trainable network

## crop_and_resize
---
> we use Tensorflow's "crop_and_resize" operation which uses bilinear interpolation to resample part of an image onto a fixed sized grid.
>>[2017 CVPR] Speed_accuracy trade-offs for modern convolutional object detectors

> The first notable change follows Huang et al. [4]. Instead of using the RoI pooling layer, we use the crop and resize operator, which crops and resizes feature maps to 14 × 14, and then max-pool them to 7 × 7 to match the input size of fc6.
>> [2017] An Implementation of Faster RCNN with Study for Region Sampling

- [2017 CVPR] Speed_accuracy trade-offs for modern convolutional object detectors
- [2017] An Implementation of Faster RCNN with Study for Region Sampling
- <https://tensorflow.google.cn/api_docs/python/tf/image/crop_and_resize>


# Loss

## IoU loss
----
- [2016 ACM MM] UnitBox_ An advanced object detection network

## GIoU loss
----
- [2019 CVPR] Generalized intersection over union_ A metric and a loss for bounding box regression

## DIoU loss, CIoU loss
---
- [2020 AAAI] Distance-IoU Loss_ Faster and better learning for bounding box regression

## bounded iou loss
---
- [2018 CVPR] Improving object localization with fitness nms and bounded iou loss

## PIoU Loss
----
- [2020 ECCV] PIoU Loss_ Towards Accurate Oriented Object Detection in Complex Environments

## Varifocal Loss, VFL
---
- [2021 CVPR] Varifocalnet: An iou-aware dense object detector


# Misalignment between  confidence and localization accuracy

## GFL, GFLv2
----
GFL and GFLv2 point out that the classification and localization branches are separately trained but compositely used in inference, so they merge the localization representation into the classification branch for a joint optimization.

- [2020] Generalized Focal Loss_ Learning Qualified and Distributed Bounding Boxes for Dense Object Detection
- [2020] Generalized Focal Loss V2_ Learning Reliable Localization Quality Estimation for Dense Object Detection

## IoUNet
----
Figure 2(a) 揭示了: 在 NMS 之前, det_boxes 和其匹配的 gt_boxes 的 iou 与 det_boxes 的分类置信度之间的关系, 两者并不是强相关的.

- [2018 ECCV] Acquisition of Localization Confidence for Accurate Object Detection


# Detetector Neck

## FPN
---
- [2017 CVPR] Feature Pyramid Networks for Object Detection

## ASFF, adaptively spatial feature fusion
----
- [2019] Learning Spatial Fusion for Single-Shot Object Detection
    - https://github.com/ruinmessi/ASFF

## NAS-FPN
----
- [2019 CVPR] NAS-FPN_ Learning scalable feature pyramid architecture for object detection

## RFP
---
- [2020] Detectors_ Detecting objects with recursive feature pyramid and switchable atrous convolution.

## BiFPN
----
- [2020 CVPR] Efficientdet: Scalable and efficient object detection

## PAN
----
- [2018 CVPR] Path aggregation network for instance segmentation

## RFB, Receptive Field Block
---


# SSD Series

## SSD
----
传统 SSD 的骨干网络为 VGG. SSD predict objects at multiple layers of the network without merging features.

- [2015] SSD_ Single Shot MultiBox Detector
- https://github.com/weiliu89/caffe/tree/ssd (该项目实现了一个 Caffe 新层, Permute)
- https://github.com/balancap/SSD-Tensorflow
- https://github.com/amdegroot/ssd.pytorch


## DSSD
---
- [2017] DSSD_ Deconvolutional single shot detector

## Others
----
- [2017] Enhancement of SSD by concatenating feature maps for object detection
- [2017] Feature-fused SSD_ fast detection for small objects
- [2018] Tiny SSD_ A Tiny Single-shot Detection Deep Convolutional Neural Network for Real-time Embedded Object Detection
- [2018] Ensemble-based Adaptive Single-shot Multi-box Detector
- *MobileNet-SSD*: [2017] Mobilenets_ Efficient convolutional neural networks for mobile vision applications
- *MobileNetV2-SSDLite*: [2018 CVPR] Mobilenetv2_ Inverted residuals and linear bottlenecks
- *MobileNeXt*: [2020] MobileNeXt_ Rethinking Bottleneck Structure for Efficient Mobile Network Design
    - https://github.com/Andrew-Qibin/ssdlite-pytorch-mobilenext


# R-CNN Series

## R-CNN
----
- [2014] Rich feature hierarchies for accurate object detection and semantic segmentation

## Fast R-CNN
----
Fast RCNN 使用 selective search 进行 region proposal.
- [2015] Fast R-CNN

## Faster R-CNN
----
Faster R-CNN 由两部分构成, 第一部分称为 RPN, 第二部分称为 R-CNN (有的文献称为 box classifier).

RPN 是全卷积的, 输出通道数 (或者说输出类别) 为 2 (前景和背景).

> We note that our algorithm allows the use of anchor boxes that are larger than the underlying receptive field when predicting large proposals. Such predictions are not impossible — one may still roughly infer the extent of an object if only the middle of the object is visible.

**References**
- [2015 NIPS] Faster R-CNN_ Towards Real-Time Object Detection with Region Proposal Networks
- https://github.com/rbgirshick/py-faster-rcnn
- https://github.com/endernewton/tf-faster-rcnn
- https://github.com/sanghoon/pva-faster-rcnn
- https://github.com/CharlesShang/TFFRCNN/

## Light-Head R-CNN
----
- [2017 Face++] Light-Head R-CNN_ In Defense of Two-Stage Object Detector

## Region Sampling
----
> NMS implicitly biases the sampling procedure toward smaller regions. Intuitively, it is more likely for large regions to overlap than small regions, so large regions have a higher chance to be suppressed.

- [2017] An Implementation of Faster RCNN with Study for Region Sampling


# YOLO Series
---
Framework | Backbone
----------|----------
YOLOv1    | /
YOLOv2    | Darknet-19
YOLOv3    | Darknet-53
YOLOv4    | CSPDarknet53

## YOLOv1
----
YOLOv1 可以视作一种 anchor-free 的方法.

- [2015] You Only Look Once_ Unified, Real-Time Object Detection

## YOLOv2
----
- [2016] YOLO9000_ Better, Faster, Stronger

## YOLOv3
----
- [2018] YOLOv3_ An Incremental Improvement
- https://github.com/ultralytics/yolov3

## Yolo-lite
---
- [2018] Yolo-lite_ a real-time object detection algorithm optimized for non-gpu computers

## YOLOv4
---
- [2020] YOLOv4_ Optimal Speed and Accuracy of Object Detection
- https://github.com/AlexeyAB/darknet

## YOLOv5
---
- https://github.com/ultralytics/YOLOv5

## Scaled-YOLOv4
---
- [2020] Scaled-YOLOv4_ Scaling Cross Stage Partial Network

## Others
---
- https://github.com/byfate/Stronger-yolo-pytorch


# Anchor-free

## FCOS
----
> In anchor-based detectors, the anchor boxes can be viewed as pre-defined sliding windows or proposals, which are classified as positive or negative patches, with an extra offsets regression to refine the prediction of bounding box locations. Therefore, the anchor boxes in these detectors may be viewed as training samples.

该论文引入了 **BPR** (Best Possible Recall) 的概念, 其定义如下:
> Here BPR is defined as the ratio of the number of ground-truth boxes a detector can recall at the most divided by all ground-truth boxes. A ground-truth box is considered being recalled if the box is assigned to at least one sample (i.e., a location in FCOS or an anchor box in anchor-based detectors) during training.

**References**:
- https://github.com/tianzhi0549/FCOS
- [2019] FCOS_ Fully Convolutional One-Stage Object Detection

## CenterNet
----
- https://github.com/xingyizhou/centernet
- [2019] Objects as Points

## CornerNet
---
CornerNet 的缺点是后处理复杂. 

- [2018 ICCV] CornerNet_ Detecting objects as paired keypoints
- https://github.com/umich-vl/CornerNet

## CornerNet-Lite
---
- [2019] CornerNet-Lite_ Efficient keypoint based object detection

## RepPoints
---
- [2019 ICCV] RepPoints_ Point set representation for object detection

## RepPoints v2
----
- [2020] RepPoints v2_ Verification Meets Regression for Object Detection

## DenseBox
---
The family of detectors have been considered unsuitable for generic object detection due to difficulty in handling overlapping bounding boxes and the recall being relatively low.

- [2015] Densebox: Unifying landmark localization with end to end object detection


# Detection and NAS

## DetNAS
---
- [2019 NeurIPS] DetNAS: Backbone search for object detection

## NAS-FPN
---
- [2019 CVPR] NAS-FPN: Learning scalable feature pyramid architecture for object detection

## NAS-FCOS
---
- [2019] NAS-FCOS: Fast neural architecture search for object detection


# Detection with transformer

## DETR
---
- [2020] End-to-end object detection with transformer

## [2020] Toward Transformer-Based Object Detection
---


# Distill

## [2021] LGD: Label-guided Self-distillation for Object Detection
----

# Rotated Bounding Box

## [2017] Learning a rotation invariant detector with rotatable bounding box
---

## [2018] Multiscale rotated bounding box-based deep learning method for detecting ship targets in remote sensing images
---

## [2018 CVPR] Rotation-sensitive regression for oriented scene text detection
---

## [2019 CVPR]  Learning roi transformer for detecting oriented objects in aerial images
---

## [2019] R3det_ Refined single-stage detector with feature refinement for rotating object
---

## [2019 CVPR] Scrdet_ Towards more robust detection for small, cluttered and rotated objects
---

## [2020 ECCV] PIoU Loss_ Towards Accurate Oriented Object Detection in Complex Environments
---
- https://github.com/clobotics/piou


# Special object detection

## [2019] Generic Product detection in retail environments
---
- https://github.com/ParallelDots/generic-sku-detection-benchmark

## [2019 CVPR] Precise Detection in Densely Packed Scenes
---


# Others

## OverFeat
---
- [2014] OverFeat_ Integrated Recognition, Localization and Detection using Convolutional Networks

## SPPNet
---
- [2014 ECCV] Spatial pyramid pooling in deep convolutional networks for visual recognition

## MultiBox
---
- [2014 CVPR] Scalable Object Detection using Deep Neural Networks

## MR-CNN
---
- [2015 ICCV] Object detection via a multi-region & semantic segmentation-aware cnn model

## ION
---
- [2015] Inside-Outside Net_ Detecting Objects in Context with Skip Pooling and Recurrent Neural Networks

## HyperNet
---
- [2016 CVPR] HyperNet_ Towards Accurate Region Proposal Generation and Joint Object Detection

## PVANet
---
- [2016 NIPS Workshop] PVANet_ Lightweight Deep Neural Networks for Real-time Object Detection

## R-FCN
---
- [2016] R-FCN_ Object Detection via Region-based Fully Convolutional Networks

## G-CNN
---
- [2015] G-CNN_ an Iterative Grid Based Object Detector

## MS-CNN
---
- [2016 ECCV] A unified multiscale deep convolutional neural network for fast object detection

## OHEM
---
- [2016 CVPR] Training region-based object detectors with online hard example mining

## Unitbox
---
提出了 IoU Loss

- [2016 ACM MM] Unitbox_ An advanced object detection network

## SqueezeDet
---
- [2016] SqueezeDet_ Unified, Small, Low Power Fully Convolutional Neural Networks for Real-Time Object Detection for Autonomous Driving

## RetinaNet, Focal Loss
---
- [2017] Focal Loss for Dense Object Detection
- https://github.com/yhenon/pytorch-retinanet

## DetNet
---
- [2018 ECCV] DetNet_ A Backbone network for Object Detection

## Pelee
---
- [2018] Pelee_ A Real-Time Object Detection System on Mobile Devices
- https://github.com/Robert-JunWang/Pelee

## IOU-Net
---
- [2018 ECCV] Acquisition of Localization Confidence for Accurate Object Detection

## RFB-Net
---
- [2018 ECCV] Receptive Field Block Net for Accurate and Fast Object Detection

## RefineDet
---
- [2018 CVPR] Single-Shot Refinement Neural Network for Object Detection

## Tiny-DSOD
---
- [2018] Tiny-dsod: Lightweight object detection for resource-restricted usages

## Trident
---
- [2019] Scale-Aware Trident Networks for Object Detection

## ThunderNet
---
- [2019 ICCV] ThunderNet_ Towards Real-time Generic Object Detection

## DuBox
---
- [2019] DuBox_ No-Prior Box Objection Detection via Residual Dual Scale Detectors

## AlignDet
---
- [2019] Revisiting Feature Alignment for One-stage Object Detection

## M2Det
---
- [2019] M2Det_ A Single-Shot Object Detector based on Multi-Level Feature Pyramid Network
- https://github.com/qijiezhao/M2Det

## EfficientDet
---
- [[2019] EfficientDet_ Scalable and Efficient Object Detection](https://arxiv.org/abs/1911.09070)
- https://github.com/toandaominh1997/EfficientDet.Pytorch
- https://github.com/signatrix/efficientdet
- https://github.com/zylo117/Yet-Another-EfficientDet-Pytorch
- https://github.com/google/automl/tree/master/efficientdet

## Spinenet
---
- [2020 CVPR] Spinenet_ Learning scale-permuted backbone for recognition and localization

## CSPNet
---
- [2020 CVPRW] CSPNet_ A new backbone that can enhance learning capability of CNN

## LRF
---
- [2019 ICCV] Learning Rich Features at High-Speed for Single-Shot Object Detection
- https://github.com/vaesl/LRF-Net

## PRN
---
- [2019 ICCVW] Enriching variety of layer-wise learning information by gradient combination

## SNIP
---
- [2018 CVPR] An analysis of scale invariance in object detection snip
- [2018 NIPS] Sniper: Efficient multi-scale training

## Region Proposal generation
---
- *SS, Selective search*: [2013 IJCV] Selective search for object recognition
- *EB, EdgeBoxes*: [2014 ECCV] Edge boxes_ Locating object proposals from edges
- *MCG, Multiscale combinatorial grouping*: [2014 CVPR] Multiscale combinatorial grouping


# 传统方法
-----

## DPM (写于 2014)
----
DPM-related methods are computationally expensive and may usually require expensive annotation in the training stage.

$\vec v_i^T = \left( {x_i^*,y_i^*} \right) - \left( {x_0^*,y_0^*} \right)$, 其中 $\left( {x_i^*,y_i^*} \right)$ 为模型中 $part_i$ 的位置, $\left( {x_0^*,y_0^*} \right)$ 为模型中 root 的位置, 故 $\vec v_i^T$ 表示 $part_i$ 相对于 root 的位置.

假设目标的 root 位置等于模型的 root 位置, 即 $\left( {x_0^*,y_0^*} \right) = \left( {{x_0},{y_0}} \right)$, 则

$$\begin{aligned}
  \left( {d{x_i},d{y_i}} \right) &= \left( {{x_i},{y_i}} \right) - \left( {x_i^*,y_i^*} \right) - \left( {{x_0},{y_0}} \right) \\ 
   &= \left( {{x_i},{y_i}} \right) - \left[ {\vec v_i^T + \left( {{x_0},{y_0}} \right)} \right] - \left( {{x_0},{y_0}} \right) \\ 
   &= \left( {{x_i},{y_i}} \right) - \left[ {2\left( {{x_0},{y_0}} \right) + \vec v_i^T} \right] \\ 
\end{aligned}$$

上面的公式存疑.

**References**:
- [2008 CVPR] A Discriminatively Trained, Multiscale, Deformable Part Model
- [2010 PAMI] Object Detection with Discriminatively Trained Part-Based Models
- [2010 CVPR] Cascade Object Detection with Deformable Part Models
