# Papers

## [2019] BERT
---
- [2019]] Bert: Pre-training of deep bidirectional transformers for language understanding

## [2019] Language models are unsupervised multitask learners
----

## [2020] Scaling laws for neural language models
----

## [2020] Language models are few-shot learners
----

# Datasets

## WMT 2014 English-to-German
---

## WMT 2014 English-to-French
----

