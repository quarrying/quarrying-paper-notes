## [2022] Towards Online Domain Adaptive Object Detection
---
本文提出了一种 Online Source-Free Domain Adaptation (Online-SFDA) 的方法.

文中提到的域适应的概念:
- UDA (Unsupervised Domain Adaptation): assume that both labelled source data and unlabeled target data are available during adaptation.
- SFDA (Source-Free Domain Adaptation): a source-trained model is adapted towards the target domain without requiring access to the source data.
- Online-SFDA: where a model is adapted to any distribution shifts encountered during deployment in an online manner.
- test-time adaptation: adaptation is performed during test-time.

UDA 的方法可以分为 3 类: adversarial training, self-training and image-to-image translation.


## [2020 ICML] Do we really need to access the source data? source hypothesis transfer for unsupervised domain adaptation
----

## [2020 CVPR] Model adaptation: Unsupervised domain adaptation without source data
----

## [2018 CVPR] MCD, Maximum classifier discrepancy
----
- [2018 CVPR] Maximum classifier discrepancy for unsupervised domain adaptation

## [2019 AAAI] DVR, Disentangled Variational Representation
----
- [2019 AAAI] Disentangled Variational Representation for Heterogeneous Face Recognition

## MMD, Maximum Mean Discrepancy
----

## [2019 ICML] Parameter-efficient transfer learning for nlp
----

## [2019 ICML] Bert and pals: Projected attention layers for efficient adaptation in multi-task learning
----

## [2020] VTAB, visual task adaptation benchmark
----
- [2020] A large-scale study of representation learning with the visual task adaptation benchmark

## [2021] LoRA,  Low-Rank Adaptation
---
- [2021] LoRA: Low-Rank Adaptation of Large Language Models

