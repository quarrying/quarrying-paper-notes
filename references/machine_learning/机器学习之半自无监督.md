# *Un-/Self-supervised representation learning*

## Exemplar CNN
---
- [2014 NIPS] Discriminative unsupervised feature learning with convolutional neural networks

## [2018 ECCV] Deep clustering for unsupervised learning of visual features
---

## InstDisc, non-parametric instance discrimination
---
> Our novel unsupervised feature learning approach is instance-level discrimination. We treat each image instance as a distinct class of its own and train a classifier to distinguish between individual instance classes.

### 算法框架
![](images/instance_discrimination.png)

### 损失函数

$$\ell_{i} = -\log \frac{\exp(\mathrm{sim}(f_i, v_{y_i})/\tau)}{\sum_{j=1}^{n} \exp(\mathrm{sim}(f_i, v_j)/\tau)}$$

其中 $n$ 等于训练集样本数目, $\mathrm{sim}(\cdot,\cdot)$ 是余弦相似度函数, $\tau$ 是温度参数. $v_j$ 是 memory bank 中的特征, $f_i$ 是网络的输出特征.

附上交叉熵损失函数的数学形式, 以作对比:

$$\ell_{i} = -\log \frac{\exp(f_i^Tw_{y_i})}{\sum_{j=1}^{C} \exp(f_i^T w_j)}$$

**References**:
- [2018 CVPR] Unsupervised feature learning via non-parametric instance discrimination

## MoCo v1
---

### 算法框架
![](images/moco.png)

$$\xi \longleftarrow m\xi + (1 - m)\theta$$

### 损失函数

$$\mathcal{L} = -\log \frac{\exp\left(\mathrm{sim}(f_\theta, \mathrm{stopgrad}(f'_\xi))/\tau\right)}{\exp\left(\mathrm{sim}(f_\theta, \mathrm{stopgrad}(f'_\xi))/\tau\right) + \sum_{j=1}^{K} \exp\left(\mathrm{sim} (f_\theta, v_{\xi, j})/\tau\right)}$$

**References**:
- [2019] Momentum Contrast for Unsupervised Visual Representation Learning
- https://github.com/facebookresearch/moco

## MoCo v2
---
- [2020] Improved baselines with momentum contrastive learning
- https://github.com/facebookresearch/moco

## SimCLR
---

### 算法框架
![](images/simclr.png)

其中 $T$ 表示数据增强模块, $f(\cdot)$ 表示 base encoder network, $g(\cdot)$ 表示 projection head.

### 损失函数
NT-Xent Loss (the normalized temperature-scaled cross entropy loss):

$$\ell_{i,j} = -\log \frac{\exp(\mathrm{sim}(z_i, z_j)/\tau)}{\sum_{k=1,k \neq i}^{2N} \exp(\mathrm{sim}(z_i, z_k)/\tau)}$$

其中 $N$ 是 batch size, $z_i$ 和 $z_j$ 来自同一个样本.

SimCLR 对 batch size 的要求的比较大, 以产生足够的反例对.

**References**:
- [2020] A simple framework for contrastive learning of visual representations
- https://github.com/google-research/simclr
- https://github.com/sthalles/SimCLR

## SimCLR v2
---
- [2020] Big Self-Supervised Models are Strong Semi-Supervised Learners

## PIRL
---
- [2020 CVPR] Self-supervised learning of pretext-invariant representations

## BYOL
---

### 算法框架
![](images/byol.png)

上分支称为 online network, 下分支称为 target network. target network 给 online netowk 提供回归的对象, target network 的参数是其本身与 online network 的指数滑动平均 , 如下: 

$$\xi \longleftarrow m\xi + (1 - m)\theta$$

### 损失函数

$$\mathcal{L} = - \mathrm{sim}(q_\theta(z_\theta), \mathrm{stopgrad}(z'_\xi)) - \mathrm{sim}(q_\theta(z'_\theta), \mathrm{stopgrad}(z_\xi))$$

**References**:
- [2020] Bootstrap Your Own Latent A New Approach to Self-Supervised Learning

## SwAV, Swapping Assignments between Views
----
> SwAV [7] incorporates clustering into a Siamese network, by computing the assignment from one view and predicting it from another view. SwAV performs online clustering under a balanced partition constraint for each batch, which is solved by the Sinkhorn-Knopp transform [10].
>> [2021 CVPR] Exploring Simple Siamese Representation Learning

**References**:
- [2020 NeurIPS] Unsupervised Learning of Visual Features by Contrasting Cluster Assignments
- [2018 ECCV] Deep clustering for unsupervised learning of visual features

## SimSiam, Simple Siamese
---

SimSiam 可以视作 BYOL without the momentum encoder; SimCLR without negative pairs; SwAV without online clustering. 

### 算法框架
![](images/simsiam.png)

$x$ 经过不同的数据增强方式得到 $x_1$ 和 $x_2$, $f$ 为编码网络, $h$ 为 prediction MLP head .

### 损失函数
定义:

$x_1$                      | $x_2$
---------------------------|---------
$z_1 \triangleq f(x_1)$    | $z_2 \triangleq f(x_2)$
$p_1 \triangleq h(f(x_1))$ | $p_2 \triangleq h(f(x_2))$

另外, 定义: 
$$\mathcal{D}(p_1, z_2) = -\frac{p_1}{\lVert p_1 \rVert_2}\frac{z_2}{\lVert z_2 \rVert_2} = -\mathrm{sim}(p_1, z_2)$$

$$\mathcal{D}(p_2, z_1) = -\frac{p_2}{\lVert p_2 \rVert_2}\frac{z_1}{\lVert z_1 \rVert_2} = -\mathrm{sim}(p_2, z_1)$$

则最终损失函数为: 
$$\mathcal{L} = \mathcal{D}(p_1, z_2) + \mathcal{D}(p_2, z_1)$$

再加上 `stop-gradient` 操作, 则为:

$$\mathcal{L} = -\mathrm{sim}(p_1, \mathrm{stopgrad}(z_2) - \mathrm{sim}(p_2, \mathrm{stopgrad}(z_1))$$


由损失函数可见, SimSiam 没有反例对 (negative sample pair).

### 源码阅读
阅读 SimSiam 的官方源码 (https://github.com/facebookresearch/simsiam), 遇到一个困惑:
由 `main_simsiam.py` 的 argparse argument 相关代码可见, 
- world_size 是 number of nodes for distributed training
- rank 是 node rank for distributed training

这两个概念具有误导性, 因为通常情况下, world_size 指的是所有节点的 gpu 的总数, rank 是 gpu 的 rank. 通读代码后, 发现 main_simsiam.py 后面对 argument 中的 world_size 和 rank 进行了调整, 调整后的意义与通常情况下的意义一致, 相关代码如下, 困惑解除.

```python
# Since we have ngpus_per_node processes per node, the total world_size
# needs to be adjusted accordingly
args.world_size = ngpus_per_node * args.world_size
# For multiprocessing distributed training, rank needs to be the
# global rank among all the processes
args.rank = args.rank * ngpus_per_node + gpu
```

**References**:
- [2021 CVPR] Exploring Simple Siamese Representation Learning
- https://github.com/facebookresearch/simsiam

## Barlow Twins
---
- [2021 ICML] Barlow twins: Self-supervised learning via redundancy reduction

## [2020 CVPR] How Useful is Self-Supervised Pretraining for Visual Task
---

## [2020] Rethinking Image Mixture for Unsupervised Visual Representation Learning
---

## [2020] What Makes for Good Views for Contrastive Learning
---

## [2018] Unsupervised representation learning by predicting image rotations
----

## [2021] SimMIM_ A Simple Framework for Masked Image Modeling
---

## [2021] BEIT
---
- [2021] Beit_ Bert pre-training of image transformers


# Self-supervised Learning Pretext task
Pretext task 或称 surrogate task

learning features using colorization is suitable for segmentation, while predicting the context works well for detection.

## relative patch prediction
---
![](images/relative_patch.png)

- [2015 ICCV] Unsupervised visual representation learning by context prediction

## solving jigsaw puzzles
---
![](images/jigsaw_puzzle.png)

最终有 $9!$ 个输出节点.

- [2016 ECCV] Unsupervised learning of visual representations by solving jigsaw puzzles

## rotation prediction
---
![](images/rotate_predict.png)

这里是直接输入旋转后的图像, 有文献是同时输入原图和旋转后的图像.

- [2018] Unsupervised representation learning by predicting image rotations

## inpainting, predicting a missing pixel
---
- [2016 CVPR] Context encoders_ Feature learning by inpainting

## colorization
---
- [2016 ECCV] Learning representations for automatic colorization
- [2016 ECCV] Colorful Image Colorization
- [2017 CVPR] Colorization as a proxy task for visual understanding

## predicting future
---
- [2018] Representation learning with contrastive predictive coding

## counting the objects
---
- [2017 ICCV] Representation learning by learning to count

## cross-channel prediction
---
- [2017 CVPR] Split-brain autoencoders: Unsupervised learning by cross-channel prediction

## learning from video
---
- [2017 CVPR] Learning features by watching objects move

## clustering
---
- [2018 ECCV] Deep clustering for unsupervised learning of visual features
- **SeLa**: [2019] Self-labelling via simultaneous clustering and representation learning
- **PCL**: [2020] Prototypical contrastive learning of unsupervised representations


# *Semi-Supervised*

**OPINIONS**: 
- 主动学习和半监督学习感觉是一体两面, 前者是 (由专家) 给困难样本打标签, 后者是 (由算法) 给简单样本打伪标签

## MixMatch
---
- [2019] MixMatch: A Holistic Approach to Semi-Supervised Learning

## ReMixMatch 
---
- [2019] ReMixMatch: Semi-Supervised Learning with Distribution Alignment and Augmentation Anchoring

## FixMatch
---
- [2020] FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence

## Self-training
---

## FlexMatch
---
- [2021 NeurIPS] Flexmatch: Boosting semi-supervised learning with curriculum pseudo labeling
