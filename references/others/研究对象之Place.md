
# Tasks
- Visual place recognition, VPR; Visual Geo-localization; VG
- Visual Localization
- Landmark Retrieval 
- Scene Classification
- Scene Understanding


# Papers

## UPerNet
----
- [2018 ECCV] Unified Perceptual Parsing for Scene Understanding


# Datasets

## Google Landmarks Dataset v2
---
**References**:
- https://github.com/cvdfoundation/google-landmark
- https://www.kaggle.com/c/landmark-retrieval-2019
- https://www.kaggle.com/c/landmark-recognition-2019


## Oxford Paris
---
The Paris Dataset consists of 6412 images collected from Flickr by searching for particular Paris landmarks.

**References**:
- http://www.robots.ox.ac.uk/~vgg/data/parisbuildings/


## Oxford Building 5K
---
The Oxford Buildings Dataset consists of 5062 images collected from Flickr by searching for particular Oxford landmarks. The collection has been manually annotated to generate a comprehensive ground truth for 11 different landmarks, each represented by 5 possible queries. This gives a set of 55 queries over which an object retrieval system can be evaluated.

**References**:
- [2007 CVPR] Object retrieval with large vocabularies and fast spatial matching
- http://www.robots.ox.ac.uk/~vgg/data/oxbuildings/


## INRIA Holidays
---
**References**:
- [2008 ECCV] Hamming embedding and weak geometric consistency for large scale image search
- http://lear.inrialpes.fr/people/jegou/data.php#holidays


# Scene Datasets

## ADE20K
---
ADE20K is composed of more than 27K images from the SUN and Places databases. Images are fully annotated with objects, spanning over 3K object categories. Many of the images also contain object parts, and parts of parts. We also provide the original annotated polygons, as well as object instances for amodal segmentation. Images are also anonymized, blurring faces and license plates.

> ADE20K is a widely-used semantic segentation dataset, covering a broad range of 150 semantic categories. It has 25K images in total, with 20K for training, 2K for validation, and another 3K for testing. (感觉和上述的描述不一致)
>> [2021] Swin Transformer_ Hierarchical Vision Transformer using Shifted Windows

**References**:
- http://groups.csail.mit.edu/vision/datasets/ADE20K/
- [2016] Semantic Understanding of Scenes through ADE20K Dataset
- [2017 CVPR] Scene Parsing through ADE20K Dataset
- http://data.csail.mit.edu/places/ADEchallenge/ADEChallengeData2016.zip
- http://data.csail.mit.edu/places/ADEchallenge/release_test.zip


## SUN 
---
> Scene categorization is a fundamental problem in computer vision. However, scene understanding research has been constrained by the limited scope of currently-used databases which do not capture the full variety of scene categories. Whereas standard databases for object categorization contain hundreds of different classes of objects, the largest available dataset of scene categories contains only 15 classes. In this paper we propose the extensive Scene UNderstanding (SUN) database that contains 899 categories and 130,519 images. We use 397 well-sampled categories to evaluate numerous state-of-the-art algorithms for scene recognition and establish new bounds of performance. We measure human scene classification performance on the SUN database and compare this with computational methods.

**References**:
- [2010 CVPR] Sun database: Large-scale scene recognition from abbey to zoo
- https://vision.princeton.edu/projects/2010/SUN/
- http://people.csail.mit.edu/jxiao/SUN/


## Cityscapes
---
Cityscapes contains 50 scenes of different views, different backgrounds and different seasons.

**References**:
- https://www.cityscapes-dataset.com/
- [2016 CVPR] The Cityscapes dataset for semantic urban scene understanding


## Foggy Cityscapes
---
**References**:
- [2018 IJCV] Semantic foggy scene understanding with synthetic data


## Places
---
205 scene categories and 2.5 millions of images with a category label.

**References**:
- [2014 NIPS] Learning deep features for scene recognition using places database


## Places2
---
**References**:
- http://places2.csail.mit.edu/index.html
- 401 scene categories in Places2 Challenge 2015
- 365 scene categories in Places2 Challenge 2016


## LSUN Dataset
---
> LSUN contains approximately one million labeled images for each of 10 scene categories (e.g., bedroom, church, or tower) and 20 object classes (e.g., bird, cat, or bus).

**References**:
- [2015] Lsun: Construction of a large-scale image dataset using deep learning with humans in the loop
- http://lsun.cs.princeton.edu/2016/


## MIT indoor
---
>MIT indoor scenes dataset contains 67 indoor scenes covering a wide range of domains including: leisure, working places, home, stores and public space categories. It consists of 15,620 images, 80 images of each class for training and 20 images for testing. 

**References**:
- [2019 CVPR] Recognizing indoor scenes

