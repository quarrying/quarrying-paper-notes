# CNN

## [1998 IEEE] LeNet-5
---
- [1998 IEEE] Gradient-based learning applied to document recognition

## [2012 NIPS] AlexNet
---
- [2012 NIPS] ImageNet Classification with Deep Convolutional Neural Networks

## [2013] NIN
----
最早提出 `1*1` 卷积.

- [2013] Network in network

## [2014 ECCV] ZFNet
---
- [2014 ECCV] Visualizing and understanding convolutional networks

## [2014] VGG
---
VGG 是 Visual Geometry Group 的简称. 常见的有: VGG16 和 VGG19, 其中数字指的是卷积层和全连接层的数目.

> So what have we gained by using, for instance, a stack of three 3*3 conv. layers instead of a single 7*7 layer? First, we incorporate three non-linear rectification layers instead of a single one, which makes the decision function more discriminative. Second, we decrease the number of parameters: assuming that both the input and the output of a three-layer 3*3 convolution stack has C channels, the stack is parametrised by 3*3^2*C^2 = 27*C^2 weights; at the same time, a single 7*7 conv. layer would require 7^2*C^2 = 49*C^2 parameters, i.e. 81% more. This can be seen as imposing a regularisation on the 7*7 conv. filters, forcing them to have a decomposition through the 3*3 filters (with non-linearity injected in between).

- [2014] Very Deep Convolutional Networks for Large-Scale Image Recognition

## [2015+] Inception
---
- [2015 CVPR] Going deeper with convolutions
- [2015 ICML] Batch normalization: Accelerating deep network training by reducing internal covariate shift
- [2015] Rethinking the inception architecture for computer vision
- [2016] Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning
- [2017 CVPR] Xception_ Deep Learning with Depthwise Separable Convolutions

## [2016+] ResNet
---
常见的有: ResNet 18/34/50/101/152/200/1001, 其中数字指的是卷积层和全连接层的数目.

name        | parameters | checkpoint size (torchvision)
------------|------------|----------------
ResNet18    | 12M        | 44.66MB
ResNet34    | 22M        | 83.27MB
ResNet50    | 25M        | 97.78MB
ResNet101   | 45M        | 170.51MB
ResNet152   | 60M        | 230.43MB
MobileNetV2 | 3.47M      | 13.55MB

参数量可以用 **预训练模型文件大小 / 4** 来估算 (2^10 约等于 1000, 模型文件中权重一般是单精度浮点型的, 有 4 字节).

在论文中常使用 **参数量** 而不是 **模型文件大小**, 是因为参数可以有不同的存储类型, 不同存储类型的字节大小不一样.

ResNet50 相对于 ResNet34 参数量没有增加多少的原因是: ReseNet34 (及 ResNet18) 使用了 BasicBlock, ResNet50 使用了 BottleNeck (包含 1×1, 3×3, and 1×1 convolutions).

**References**
- [2016 CVPR] Deep residual learning for image recognition
- [2016 ECCV] Identity mappings in deep residual networks
- [2016] Aggregated Residual Transformations for Deep Neural Networks
- [2016 BMVC] Wide Residual Networks

## [2016] DenseNet
---
为 ImageNet 设计的 DenseNet (参考文献中的 Table 1), 前两层为: `7 × 7 conv, stride 2` 和 `3 × 3 max pool, stride 2`. 在 [2018 CVPR] Scale-Transferrable Object Detection 中提到这种设计并不好, 并用三个连续的卷积替换之:

> Inspired by DSOD [27], we replace the input layers (7 × 7 convolution layer, stride = 2 followed by a 3 × 3 max pooling layer, stride = 2) into three 3×3 convolution layers and one 2×2 mean pooling layer. The stride of the first convolution layer is 2 and the others are 1. The output channels for all three convolution layers are 64. We call these layers “stem block”. Table 1 depicts our network architecture in detail. Experiments show that this simple substitution can significantly improve the accuracy of object detection (see Table 3 in ablation study). One explanation could be that the input layers in the original DenseNet-169 have lost much information due to two consecutive down sampling. This will impair the performance of object detection, especially for small objects.

- [2016] Densely Connected Convolutional Networks

## [2017] DPN
---
- [2017] Dual Path Networks

## [2017] GUNN
---
- [2017] Gradually Updated Neural Networks for Large-Scale Image Recognition

## [2017] SENet
---
- [2017] Squeeze-and-Excitation Networks

## [2017] DLA
---
- [2017] Deep Layer Aggregation

## [2018] BAM, CBAM
---
- [2018 BMVC] BAM_ Bottleneck Attention Module
- [2018 ECCV] CBAM_ Convolutional Block Attention Module

## [2021 CVPR] Coordinate attention
---
- [2021 CVPR] Coordinate attention for efficient mobile network design

## [2018 ECCV] IBN-Net
---
- [2018 ECCV] Two at Once_ Enhancing Learning and Generalization Capacities via IBN-Net

## [2019] SKNet
---
> SKNet convolves the feature map with 3 × 3 and 5 × 5 kernels respectively, and then obtains the weight of the two convolution results through GAP to do attention.

- [2019] Selective Kernel Networks

## [2019] Res2Net
---
- [2019] Res2Net_ A New Multi-scale Backbone Architecture

## [2019] GCNet
---
- [2019] GCNet_ Non-local Networks Meet Squeeze-Excitation Networks and Beyond

## [2020] ResNeSt
---
- [2020] ResNeSt_ Split-Attention Networks

## [2019] SGE-NET
----
- [2019] Spatial group-wise enhance: Improving semantic feature learning in convolutional networks

## [2022 CVPR] ConvNeXt
---
- [2022 CVPR] A ConvNet for the 2020s

## [2022] FocalNet
----
- [2022] Focal Modulation Networks

## [2022] InternImage
----
核心组件为 DCNv3.

模型           | 参数量
---------------|-----
InternImage-T  | 30M
InternImage-S  | 50M
InternImage-B  | 97M
InternImage-L  | 223M
InternImage-XL | 335M
InternImage-H  | 1.08B

- [2022] InternImage_ Exploring Large-Scale Vision Foundation Models with Deformable Convolutions

## [2022] MetaFormer
---
- [2022] MetaFormer Baselines for Vision
- https://github.com/sail-sg/metaformer


# 轻量型 CNN

## [2016] SqueezeNet
---
- [2016] SqueezeNet_ AlexNet-level accuracy with 50x fewer parameters and less than 0.5MB model size

## [2017] IGCV
---
- [2017 ICCV] Interleaved Group Convolutions for Deep Neural Networks
- [2018] IGCV2_ Interleaved Structured Sparse Convolutional Neural Networks
- [2018] IGCV3_ Interleaved low-rank group convolutions for efficient deep neural networks

## [2017] CondenseNet
---
- [2017] CondenseNet_ An Efficient DenseNet using Learned Group Convolutions

## [2018] SqueezeNext
---
- [2018] SqueezeNext_ Hardware-Aware Neural Network Design

## [2017+] MobileNet
---
- [2017] MobileNets_ Efficient Convolutional Neural Networks for Mobile Vision Applications
- [2018] Inverted Residuals and Linear Bottlenecks_ Mobile Networks for Classification, Detection and Segmentation
- [2019] Searching for MobileNetV3

## [2017+] ShuffleNet
---
- [2017] ShuffleNet_ An Extremely Efficient Convolutional Neural Network for Mobile Devices
- [2018] ShuffleNet V2_ Practical Guidelines for Efficient CNN Architecture Design

## [2018] MobileFaceNets
---
- [2018] MobileFaceNets_ Efficient CNNs for Accurate Real-time Face Verification on Mobile Devices

## [2018] MnasNet
---
- [2018] MnasNet_ Platform-Aware Neural Architecture Search for Mobile

## [2018 NIPS] ChannelNets
---
- [2018 NIPS] ChannelNets_ Compact and Efficient Convolutional Neural Networks via Channel-Wise Convolutions

## [2020] MobileNeXt
---
- [[2020] MobileNeXt_ Rethinking Bottleneck Structure for Efficient Mobile Network Design](https://arxiv.org/abs/2007.02269)
- https://github.com/zhoudaquan/rethinking_bottleneck_design

## [2020 CVPRW] CSPNet
---
本文提出了一种名为 Cross Stage Partial Network (CSPNet) 的网络设置, 其结构大致为: 将输入在通道维度上分为两部分, 第一部分不进行任何操作, 第二部分按原来的网络连接操作, 最终的输出是第一部分本身与第二部分输出的某种融合 (见文献中的公式(4)). 作者在 ImageNet 数据集上做了充分的实验, 验证了 DenseNet, ResNet 和 ResNeXt 等经典网络在引入 CSPNet 之后可以在降低计算量的同时提升准确率. 论文还提出了一个新的特征金字塔融合策略, Exact Fusion Model (EFM, 其根据与 ground truth bounding box 匹配的 anchor 的尺寸来选择性的融合某些尺度的特征), 并通过实验验证了其在目标检测任务 (MS COCO 数据集) 中的有效性.

FACTS: 
> For segmentation tasks, since pixel-level labels usually do not contain global information, it is usually more preferable to consider larger patches for better information retrieval [21] ([2016 ICLR] ParseNet: Looking wider to see better). However, for tasks like image classification and object detection, some critical information can be obscure when observed from image-level and bounding box-level labels. Li et al. [15] ([2018 CVPR] Tell me where to look: Guided attention inference network) found that CNN can be often distracted when it learns from image-level labels and concluded that it is one of the main reasons that two-stage object detectors outperform one-stage object detectors.

FACTS: CSPNet 在 YOLOV4 和 Scaled-YOLOV4 中均有见 (这三篇论文的作者来自同一团队).


- [2020 CVPRW] CSPNet_ A new backbone that can enhance learning capability of CNN


# MLP

## [2021 NeurIPS] MLP-Mixer
----
- [2021 NeurIPS] Mlp-mixer: An all-mlp architecture for vision


# Convolution

## [2017] Deformable convolution
----
- [2017] Deformable Convolutional Networks
- [2019 CVPR] Deformable convnets v2: More deformable, better results

## [2020] SlimConv
---
- [如何评价新型即插即用模块SlimConv？](https://www.zhihu.com/question/393850908 )
- [2020] SlimConv: Reducing Channel Redundancy in Convolutional Neural Networks by Weights Flipping

## [2019] SKConv, Selective Kernel Convolution
---
- [2019 CVPR] Selective Kernel Networks

## [2019 BMVC] MixConv
---
- [2019 BMVC] MixConv: Mixed Depthwise Convolutional Kernels

## [2019 ICCV] OctConv, Octave Convolution
---
- [如何评价最新的Octave Convolution？](https://www.zhihu.com/question/320462422)
- [2019 ICCV] Drop an Octave: Reducing Spatial Redundancy in Convolutional Neural Networks with Octave Convolution


# Attention

## [2017] SE
---
- [2017] Squeeze-and-Excitation Networks

## [2018 ECCV] CBAM
---
- [2018 ECCV] CBAM_ Convolutional Block Attention Module

## [2021 ICCV] Residual Attention
---
- [2021 ICCV] Residual Attention: A Simple but Effective Method for Multi-Label Recognition

## [2018] CCNet
---
- [2018] CCNet_ Criss-Cross Attention for Semantic Segmentation

## [2020] AFF
---
- [2020] Attentional Feature Fusion
- https://github.com/YimianDai/open-aff

## [2018 CVPR] Non-local neural networks
---

## [2019 CVPR] DANet
---
- [2019 CVPR] Dual attention network for scene segmentation


# Pooling

## [2013] Stochastic pooling
---
- [2013] Stochastic pooling for regularization of deep convolutional neural networks

## [2014] Lp Pooling
---
- [2014] Learned-Norm Pooling for Deep Feedforward and Recurrent Neural Networks

## [2014 ECCV] SPP, Spatial pyramid pooling
---
空间金字塔池化（Spatial pyramid pooling；SPP），其思想来自于（Spatial pyramid matching；SPM）。

- [2014 ECCV] Spatial pyramid pooling in deep convolutional networks for visual recognition

## [2014] Mixed Pooling
---
- [2014] Mixed Pooling for Convolutional Neural Networks
- [2015] Generalizing Pooling Functions in Convolutional Neural Networks_ Mixed, Gated, and Tree

## [2015] FMP, Fractional Max-Pooling
---
- [2015] Fractional Max-Pooling

## [2018] Alpha-Pooling
---
- [2018] Alpha-Pooling for Convolutional Neural Networks

## [2018] GNAP, Global Norm-Aware Pooling
---
- [2018] Global Norm-Aware Pooling for Pose-Robust Face Recognition at Low False Positive Rate

## [2018 CVPR] DPP, Detail-Preserving Pooling
---
- [2018 CVPR] Detail-Preserving Pooling in Deep Networks

## [2015+] Bilinear Pooling Series
----
- [2015] Bilinear CNNs for Fine-grained Visual Recognition
- [2016] Compact Bilinear Pooling
- [2016] Low-rank Bilinear Pooling for Fine-Grained Classification
- [2016] Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding
- [2017 BMVC] Improved Bilinear Pooling with CNNs
- [2017 ICLR] Hadamard Product for Low-rank Bilinear Pooling
- [2018] Hierarchical Bilinear Pooling for Fine-Grained Visual Recognition


# Activation Function

## [2013 ICML] Leaky ReLU
---
- [2013 ICML] Rectifier nonlinearities improve neural network acoustic models

## [2014] Thresholded ReLU
---
- [2014] Zero-Bias Autoencoders and the Benefits of Co-Adapting Features

## [2015] PReLU, Parametric ReLU
---
- [2015] Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification

## [2015] ELU, Exponential Linear Unit
---
- [2015] Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)

## [2015] S-shaped ReLU
---
- [2015] Deep Learning with S-shaped Rectified Linear Activation Units

## [2016 ECCV] MPELU, Multiple Parametric Exponential Linear Unit
---
- [2016 ECCV] Improving Deep Neural Network with Multiple Parametric Exponential Linear Units

## [2017] SELU, Self-Normalizing Linear Unit
---
- [2017] Self-Normalizing Neural Networks

## [2017] Swish
---
- [2017] Swish_ a Self-Gated Activation Function

## [2018] PoLU, Power Linear Unit
---
- [2018] Training Neural Networks by Using Power Linear Units (PoLUs)

## [2019] Mish
---
- [2019] Mish_ A self regularized non-monotonic neural activation function

## [2021] Squareplus
----
ReLU 的平滑近似

- [[2021] Squareplus: A Softplus-Like Algebraic Rectifier](https://arxiv.org/abs/2112.11687)

## [2015] Empirical Evaluation of Rectified Activations in Convolution Network
---

## [2016 ICML] Noisy Activation Functions
---

## [2016] Revise Saturated Activation Functions
---

## [2018] Activation Functions_ Comparison of trends in Practice and Research for Deep Learning
---

## [2018] Deep Neural Networks with Data Dependent Implicit Activation Function
---

## [2018] The Quest for the Golden Activation Function
---

## [2016] GELU, Gaussian Error Linear Unit
---
GPT 中有用到这个激活函数.

- [2016] Bridging nonlinearities and stochastic regularizers with gaussian error linear units


# NAS, Neutral Architecture Search

## [2018 CVPR] NASNet
---
- [2018 CVPR] Learning transferable architectures for scalable image recognition

## [2018] DARTS
---
- [2018] DARTS: Differentiable architecture search

## [2019] PC-DARTS
---
- [2019] PC-DARTS: Partial channel connections for memory-efficient differentiable architecture search

## [2019 ICCV] MobileNetV3
---
- [2019 ICCV] Searching for mobilenetv3

## [2019 ICML] EfficientNet
---
先用 NAS 搜索得到 EfficientNet-B0, 然后再按一定的 scaling 策略, 得到: EfficientNet-B1 到 EfficientNet-B7.

- [2019 ICML] Rethinking model scaling for convolutional neural networks

## [2019 CVPR] Mnasnet
----
- [2019 CVPR] Mnasnet_ Platform-aware neural architecture search for mobile

## [2020 CVPR] RegNet
---
- [2020 CVPR] Designing network design spaces


# SNN, Spiking Neural Networks

## [2025] SpikeYOLO
---
> SpikeYOLO integrates the macro design of the YOLOv8 with the micro design of Meta-SpikeFormer.

- [2025] Integer-Valued Training and Spike-Driven Inference Spiking Neural Network for High-performance and Energy-efficient Object Detection

## [2024 CVPR] Are Conventional SNNs Really Efficient_ A Perspective from Network Quantization
---

