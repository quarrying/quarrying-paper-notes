# CNN

## LeNet-5
---
- [1998 IEEE] Gradient-based learning applied to document recognition

## AlexNet
---
- [2012 NIPS] ImageNet Classification with Deep Convolutional Neural Networks

## NIN
----
最早提出 `1*1` 卷积.

- [2013] Network in network

## ZFNet
---
- [2014 ECCV] Visualizing and understanding convolutional networks

## VGG
---
VGG 是 Visual Geometry Group 的简称. 常见的有: VGG16 和 VGG19, 其中数字指的是卷积层和全连接层的数目.

> So what have we gained by using, for instance, a stack of three 3*3 conv. layers instead of a single 7*7 layer? First, we incorporate three non-linear rectification layers instead of a single one, which makes the decision function more discriminative. Second, we decrease the number of parameters: assuming that both the input and the output of a three-layer 3*3 convolution stack has C channels, the stack is parametrised by 3*3^2*C^2 = 27*C^2 weights; at the same time, a single 7*7 conv. layer would require 7^2*C^2 = 49*C^2 parameters, i.e. 81% more. This can be seen as imposing a regularisation on the 7*7 conv. filters, forcing them to have a decomposition through the 3*3 filters (with non-linearity injected in between).

- [2014] Very Deep Convolutional Networks for Large-Scale Image Recognition

## Inception
---
- [2015 CVPR] Going deeper with convolutions
- [2015 ICML] Batch normalization: Accelerating deep network training by reducing internal covariate shift
- [2015] Rethinking the inception architecture for computer vision
- [2016] Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning
- [2017 CVPR] Xception_ Deep Learning with Depthwise Separable Convolutions

## ResNet
---
常见的有: ResNet 18/34/50/101/152/200/1001, 其中数字指的是卷积层和全连接层的数目.

name        | parameters | checkpoint size (torchvision)
------------|------------|----------------
ResNet18    | 12M        | 44.66MB
ResNet34    | 22M        | 83.27MB
ResNet50    | 25M        | 97.78MB
ResNet101   | 45M        | 170.51MB
ResNet152   | 60M        | 230.43MB
MobileNetV2 | 3.47M      | 13.55MB

参数量可以用 **预训练模型文件大小 / 4** 来估算 (2^10 约等于 1000, 模型文件中权重一般是单精度浮点型的, 有 4 字节).

在论文中常使用 **参数量** 而不是 **模型文件大小**, 是因为参数可以有不同的存储类型, 不同存储类型的字节大小不一样.

ResNet50 相对于 ResNet34 参数量没有增加多少的原因是: ReseNet34 (及 ResNet18) 使用了 BasicBlock, ResNet50 使用了 BottleNeck (包含 1×1, 3×3, and 1×1 convolutions).

**References**
- [2016 CVPR] Deep residual learning for image recognition
- [2016 ECCV] Identity mappings in deep residual networks
- [2016] Aggregated Residual Transformations for Deep Neural Networks
- [2016 BMVC] Wide Residual Networks

## DenseNet
---
为 ImageNet 设计的 DenseNet (参考文献中的 Table 1), 前两层为: `7 × 7 conv, stride 2` 和 `3 × 3 max pool, stride 2`. 在 [2018 CVPR] Scale-Transferrable Object Detection 中提到这种设计并不好, 并用三个连续的卷积替换之:

> Inspired by DSOD [27], we replace the input layers (7 × 7 convolution layer, stride = 2 followed by a 3 × 3 max pooling layer, stride = 2) into three 3×3 convolution layers and one 2×2 mean pooling layer. The stride of the first convolution layer is 2 and the others are 1. The output channels for all three convolution layers are 64. We call these layers “stem block”. Table 1 depicts our network architecture in detail. Experiments show that this simple substitution can significantly improve the accuracy of object detection (see Table 3 in ablation study). One explanation could be that the input layers in the original DenseNet-169 have lost much information due to two consecutive down sampling. This will impair the performance of object detection, especially for small objects.

- [2016] Densely Connected Convolutional Networks

## DPN
---
- [2017] Dual Path Networks

## GUNN
---
- [2017] Gradually Updated Neural Networks for Large-Scale Image Recognition

## SENet
---
- [2017] Squeeze-and-Excitation Networks

## DLA
---
- [2017] Deep Layer Aggregation

## BAM, CBAM
---
- [2018 BMVC] BAM_ Bottleneck Attention Module
- [2018 ECCV] CBAM_ Convolutional Block Attention Module

## Coordinate attention
---
- [2021 CVPR] Coordinate attention for efficient mobile network design


## IBN-Net
---
- [2018 ECCV] Two at Once_ Enhancing Learning and Generalization Capacities via IBN-Net

## SKNet
---
> SKNet convolves the feature map with 3 × 3 and 5 × 5 kernels respectively, and then obtains the weight of the two convolution results through GAP to do attention.

- [2019] Selective Kernel Networks

## Res2Net
---
- [2019] Res2Net_ A New Multi-scale Backbone Architecture

## GCNet
---
- [2019] GCNet_ Non-local Networks Meet Squeeze-Excitation Networks and Beyond

## ResNeSt
---
- [2020] ResNeSt_ Split-Attention Networks

## SGE-NET
----
- [2019] Spatial group-wise enhance: Improving semantic feature learning in convolutional networks

## [2022 CVPR] ConvNeXt
---
- [2022 CVPR] A ConvNet for the 2020s

## [2022] FocalNet
----
- [2022] Focal Modulation Networks

## [2022] InternImage
----
核心组件为 DCNv3.

模型           | 参数量
---------------|-----
InternImage-T  | 30M
InternImage-S  | 50M
InternImage-B  | 97M
InternImage-L  | 223M
InternImage-XL | 335M
InternImage-H  | 1.08B

- [2022] InternImage_ Exploring Large-Scale Vision Foundation Models with Deformable Convolutions

## MetaFormer
---
- [2022] MetaFormer Baselines for Vision
- https://github.com/sail-sg/metaformer


# 轻量型 CNN

## SqueezeNet
---
- [2016] SqueezeNet_ AlexNet-level accuracy with 50x fewer parameters and less than 0.5MB model size

## IGCV
---
- [2017 ICCV] Interleaved Group Convolutions for Deep Neural Networks
- [2018] IGCV2_ Interleaved Structured Sparse Convolutional Neural Networks
- [2018] IGCV3_ Interleaved low-rank group convolutions for efficient deep neural networks

## CondenseNet
---
- [2017] CondenseNet_ An Efficient DenseNet using Learned Group Convolutions

## SqueezeNext
---
- [2018] SqueezeNext_ Hardware-Aware Neural Network Design

## MobileNet
---
- [2017] MobileNets_ Efficient Convolutional Neural Networks for Mobile Vision Applications
- [2018] Inverted Residuals and Linear Bottlenecks_ Mobile Networks for Classification, Detection and Segmentation
- [2019] Searching for MobileNetV3

## ShuffleNet
---
- [2017] ShuffleNet_ An Extremely Efficient Convolutional Neural Network for Mobile Devices
- [2018] ShuffleNet V2_ Practical Guidelines for Efficient CNN Architecture Design

## MobileFaceNets
---
- [2018] MobileFaceNets_ Efficient CNNs for Accurate Real-time Face Verification on Mobile Devices

## MnasNet
---
- [2018] MnasNet_ Platform-Aware Neural Architecture Search for Mobile

## ChannelNets
---
- [2018 NIPS] ChannelNets_ Compact and Efficient Convolutional Neural Networks via Channel-Wise Convolutions

## MobileNeXt
---
- [[2020] MobileNeXt_ Rethinking Bottleneck Structure for Efficient Mobile Network Design](https://arxiv.org/abs/2007.02269)
- https://github.com/zhoudaquan/rethinking_bottleneck_design


# MLP

## MLP-Mixer
----
- [2021 NeurIPS] Mlp-mixer: An all-mlp architecture for vision


# Convolution

## Deformable convolution
----
- [2017] Deformable Convolutional Networks
- [2019 CVPR] Deformable convnets v2: More deformable, better results

## SlimConv
---
- [如何评价新型即插即用模块SlimConv？](https://www.zhihu.com/question/393850908 )
- [2020] SlimConv: Reducing Channel Redundancy in Convolutional Neural Networks by Weights Flipping

## SKConv, Selective Kernel Convolution
---
- [2019 CVPR] Selective Kernel Networks

## MixConv
---
- [2019 BMVC] MixConv: Mixed Depthwise Convolutional Kernels

## OctConv, Octave Convolution
---
- [如何评价最新的Octave Convolution？](https://www.zhihu.com/question/320462422)
- [2019 ICCV] Drop an Octave: Reducing Spatial Redundancy in Convolutional Neural Networks with Octave Convolution


# Attention

## Overview
----
- 注意力分为: Hard-attention, Soft-attention, Self-attention
- 空间注意力, 通道注意力
- 注意力与显著性之间的区别与联系?

## Others
----
- SE: [2017] Squeeze-and-Excitation Networks
- CBAM: [2018 ECCV] CBAM_ Convolutional Block Attention Module
- [2021 ICCV] Residual Attention: A Simple but Effective Method for Multi-Label Recognition
- CCNet: [2018] CCNet_ Criss-Cross Attention for Semantic Segmentation
- AFF: [2020] Attentional Feature Fusion
    - https://github.com/YimianDai/open-aff
- [2018 CVPR] Non-local neural networks
- DANet: [2019 CVPR] Dual attention network for scene segmentation
- [2019 ICCV] Attention augmented convolutional networks


# Pooling

## Stochastic pooling
---
- [2013] Stochastic pooling for regularization of deep convolutional neural networks

## Lp Pooling
---
- [2014] Learned-Norm Pooling for Deep Feedforward and Recurrent Neural Networks

## SPP, Spatial pyramid pooling
---
空间金字塔池化（Spatial pyramid pooling；SPP），其思想来自于（Spatial pyramid matching；SPM）。

- [2014 ECCV] Spatial pyramid pooling in deep convolutional networks for visual recognition

## Mixed Pooling
---
- [2014] Mixed Pooling for Convolutional Neural Networks
- [2015] Generalizing Pooling Functions in Convolutional Neural Networks_ Mixed, Gated, and Tree

## FMP, Fractional Max-Pooling
---
- [2015] Fractional Max-Pooling

## Alpha-Pooling
---
- [2018] Alpha-Pooling for Convolutional Neural Networks

## GNAP, Global Norm-Aware Pooling
---
- [2018] Global Norm-Aware Pooling for Pose-Robust Face Recognition at Low False Positive Rate

## DPP, Detail-Preserving Pooling
---
- [2018 CVPR] Detail-Preserving Pooling in Deep Networks

## Bilinear Pooling
----
- [2015] Bilinear CNNs for Fine-grained Visual Recognition
- [2016] Compact Bilinear Pooling
- [2016] Low-rank Bilinear Pooling for Fine-Grained Classification
- [2016] Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding
- [2017 BMVC] Improved Bilinear Pooling with CNNs
- [2017 ICLR] Hadamard Product for Low-rank Bilinear Pooling
- [2018] Hierarchical Bilinear Pooling for Fine-Grained Visual Recognition


# Activation Function

## [2013 ICML] Leaky ReLU
---
- [2013 ICML] Rectifier nonlinearities improve neural network acoustic models

## [2014] Thresholded ReLU
---
- [2014] Zero-Bias Autoencoders and the Benefits of Co-Adapting Features

## [2015] PReLU, Parametric ReLU
---
- [2015] Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification

## [2015] ELU, Exponential Linear Unit
---
- [2015] Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)

## [2015] S-shaped ReLU
---
- [2015] Deep Learning with S-shaped Rectified Linear Activation Units

## [2016 ECCV] MPELU, Multiple Parametric Exponential Linear Unit
---
- [2016 ECCV] Improving Deep Neural Network with Multiple Parametric Exponential Linear Units

## [2017] SELU, Self-Normalizing Linear Unit
---
- [2017] Self-Normalizing Neural Networks

## [2017] Swish
---
- [2017] Swish_ a Self-Gated Activation Function

## [2018] PoLU, Power Linear Unit
---
- [2018] Training Neural Networks by Using Power Linear Units (PoLUs)

## [2019] Mish
---
- [2019] Mish_ A self regularized non-monotonic neural activation function

## [2021] Squareplus
----
ReLU 的平滑近似

- [[2021] Squareplus: A Softplus-Like Algebraic Rectifier](https://arxiv.org/abs/2112.11687)

## [2015] Empirical Evaluation of Rectified Activations in Convolution Network
---

## [2016 ICML] Noisy Activation Functions
---

## [2016] Revise Saturated Activation Functions
---

## [2018] Activation Functions_ Comparison of trends in Practice and Research for Deep Learning
---

## [2018] Deep Neural Networks with Data Dependent Implicit Activation Function
---

## [2018] The Quest for the Golden Activation Function
---

## [2016] GELU, Gaussian Error Linear Unit
---
GPT 中有用到这个激活函数.

- [2016] Bridging nonlinearities and stochastic regularizers with gaussian error linear units


# NAS, Neutral Architecture Search

## NASNet
---
- [2018 CVPR] Learning transferable architectures for scalable image recognition

## DARTS
---
- [2018] DARTS: Differentiable architecture search

## PC-DARTS
---
- [2019] PC-DARTS: Partial channel connections for memory-efficient differentiable architecture search

## MobileNetV3
---
- [2019 ICCV] Searching for mobilenetv3

## EfficientNet
---
先用 NAS 搜索得到 EfficientNet-B0, 然后再按一定的 scaling 策略, 得到: EfficientNet-B1 到 EfficientNet-B7.

- [2019 ICML] Rethinking model scaling for convolutional neural networks

## Mnasnet
----
- [2019 CVPR] Mnasnet_ Platform-aware neural architecture search for mobile

## RegNet
---
- [2020 CVPR] Designing network design spaces
